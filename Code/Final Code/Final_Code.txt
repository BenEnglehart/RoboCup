import numpy as np
from scipy.spatial import distance as dist
from scipy.interpolate import interp1d
import copy
import math
import cv2
import serial
import time
from fractions import gcd
import sys
from numpy.linalg import multi_dot
from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QHBoxLayout, QWidget, QPushButton, QMainWindow
from PyQt5.QtWidgets import QSizePolicy, QSlider, QRadioButton, QGridLayout, QButtonGroup, QCheckBox
from PyQt5.QtGui import QPainter, QColor, QFont, QPalette, QPixmap, QPen, QImage, QIcon, QBrush, QPen, QPainterPath
from PyQt5.QtCore import QObject, QThread, pyqtSignal, QSize, Qt
import matplotlib.pyplot as plt
from timeit import default_timer as timer   
from scipy import interpolate               
import random                               
from PyQt5 import QtCore, QtGui, QtWidgets

KL25=serial.Serial('COM7',19200,timeout=1)#open serial port
# two Lists used for real time plottting of the left motor and right motor
Rmotor= []
Lmotor= []

class robotClass:
    def __init__(self, pos = [], radius = 0, team = '-no team!-', ID = 0):
        self.pos = pos # centre coordinates [x,y]
        self.radius = radius # calculated radius of robot (based on centre dot)
        self.team = team # team 'B'  or 'Y'
        self.angle = 999 # angle of orientation 
        self.ID = ID # ID of robot on a team
        # ID markings
        self.circles = [] # [x,y,color]

    # this is a method to add a new circle for IDing the robot
    def newMarking(self, circle = [0,0,[0,0,0]]): 
        self.circles.append(circle)

class ballClass:
    def __init__(self, x = 0, y = 0):
        self.pos = [x, y]

roboList = []       # holds all robots currently seen- resets every loop
roboListGUI = []       # holds all robots currently seen- resets every loop
roboIDmarks = []    # holds all potential robot ID marks seen ('G' or 'P')
ball = None         # holds ball position in ballClass type object
ballGUI= None
IDdRobots = []      # potentially used for previous state- probably updated every loop

param1val = 80
param2val = 15
valueMin = 125

xgoalie = []
ygoalie = []
goalie_index=0
goalie_flag=0

def colorID(hue, sat, val):

    #print('initial')
    #print(hue)
    #print(sat)
    #print(val)

    color = 'X' # Default case, 'X' will print an error for an unrecognized element
    if(val > 0):
    #if(val > valueMin):
        if (hue < 140 and hue > 50 and sat >= 30):
        #if (hue < 250 and hue >= 150):
            color = 'B' # Blue team circle
            #print(hue,sat,val)
     #       print('BLUE')
        elif (hue > 140 and sat > 80):
            color = 'Y' # Yellow team circle
            #print(hue,sat,val)
      #      print('YELLOW')
        elif (hue >= 100 and sat<170) or (hue < 10):
            color = 'P' # Purple ID circle
            #print(hue,sat,val)
       #     print('PINK')
        elif (hue > 20 and sat<150): #or (hue>130 and sat<5):
            color = 'G' # Green ID circle
            #print(hue,sat,val)
        #    print('GREEN')
        #elif ((hue <= 12 and hue >= 3 and sat > 40) or 
              #(hue <=35 and hue > 24 and sat < 100) or (hue <= 24 and hue > 12)):
        elif (hue < 20 and sat < 200):
            color = 'O' # Ball!
            #print(hue,sat,val)
         #   print('ORANGE')
            #print(hue,sat,val)
        #else:
        #    print("unrecognized",hue,sat,val) # good for debugging unrecognized circles
        #    cv2.waitKey(1000)
    return color 

# IDcircle()
# K.C. & E.H., Nov. 24th, 2018
# This function identifies any given circle based on its color and location. Although it
# does not return anything, it assigns the circle to its appropriate global variable
# (a robot object, ID mark list or ball object).
#              (input) -> (function) -> (output)
#               [x,y,r] -> ID_circle() -> none
# v1:
# Must implement all identifying functions. closestBot() is not fully developed, and must
# be added when completed.
def IDcircle(img, circle):
    global ball # so we can assign the ball its position globally

    x=int(circle[0])
    y=int(circle[1])
    #r=int(circle[2])
    
    # Getting spaced pixels within the circle
    #diffx = [int(x+r/2), int(x-r/2)]
    #for idx,posx in list(enumerate(diffx)):
    #    if(posx >= len(img[0])):
    #        diffx[idx] = x
    #    elif(posx < 0):
    #        diffx[idx] = 0
    #diffy = [int(y+r/2), int(y-r/2)]
    #for idx2,posy in list(enumerate(diffy)):
    #    if(posy >= len(img)):
    #        diffy[idx2] = y
    #    elif(posy < 0):
    #        diffy[idx2] = 0
    #print("Colors",img[y,x,0],img[y,x,1],img[y,x,2])
    hue = img[y,x,0]
    sat = img[y,x,1]
    val = img[y,x,2]
    # taking the average hue, saturation and value of a circle
    #hue = sum([img[y,x,0],img[y,diffx[0],0],img[y,diffx[1],0],img[diffy[0],x,0],img[diffy[1],x,0]])/5
    #sat = sum([img[y,x,1],img[y,diffx[0],1],img[y,diffx[1],1],img[diffy[0],x,1],img[diffy[1],x,1]])/5
    #val = sum([img[y,x,2],img[y,diffx[0],2],img[y,diffx[1],2],img[diffy[0],x,2],img[diffy[1],x,2]])/5

    # getting the color of the circle with the averaged pixel
    color = colorID(hue, sat, val)
    #print(hue, sat, val,'   so the Circle is ', color)
    #cv2.waitKey(1000)

    # if its blue or (if its yellow) --> Robot center/new robot
    if (color == 'B') or (color == 'Y'):
        # passes in position [x,y], radius and color
        # where the radius is calced with: 25 radius centre in 85 radius robot so ~ 3.4 times radius
        roboList.append(robotClass([x,y],circle[2]*4,color))
        #print('Robot seen!')

    # if green or purple --> Robot ID marking
    elif (color == 'G') or (color == 'P'):        
        roboIDmarks.append([x,y,color])
            
    # if orange --> Ball location
    elif (color == 'O'):
        ball = ballClass(x,y)

# assignIDmarks()
# E.H., Dec, 2018
# This function cycles through the globally stored roboIDmarks list and assigns them to the
# closest available robot, provided they don't already have 4 assigned
def assignIDmarks(robot):
    #if isinstance(roboList, type(None)) == 0:
        # Assign each robot its four closest marks
        #for robot in roboList:
    closestMarks = [] # indices of the closest four marks to the robot center
                                # [index in roboIDmarks, euclidean distance]
    #furthestMark = [0,0] # [index in closestMarks, euclidean distance]

    # Assign this robot its four closest marks
    #for i, mark in enumerate(list(roboIDmarks)):
    for mark in roboIDmarks:
        markDist = dist.euclidean([mark[0],mark[1]],robot.pos)

        if(markDist < robot.radius and len(robot.circles) < 4):
            robot.newMarking(mark)
            closestMarks.append(markDist)
        elif(markDist < robot.radius):
            for i, currentcircle in enumerate(list(robot.circles)):
                if markDist < closestMarks[i]:
                    robot.circles[i] = mark
                    closestMarks[i] = markDist


        # If there aren't already four marks given to the robot, 
        # just give it whatever is available in order to initialize robot.circles[]
        #if len(robot.circles) < 4:
        #    if markDist < robot.radius:
        #        robot.newMarking(mark)
        #    closestMarks[i] = [i, markDist]
        #    if markDist > furthestMark[1]:
        #        furthestMark = [i, markDist]

        ## If there is a closer value than the furthest currently in robot.circles[]
        ## replace the current furthest with this new one 
        #elif markDist < furthestMark[1]:
        #    if markDist < robot.radius:
        #        robot.circles[furthestMark[0]] = mark
        #    closestMarks[furthestMark[0]] = [i, markDist]

        #    furthestMark[1] = markDist

        #    # redetermine the furthest mark within the current closest marks
        #    for j, qark in enumerate(closestMarks):
        #        if qark[1] > furthestMark[1]:
        #            furthestMark = [j, qark[1]]

        #else:
            #print(robot.radius)
                
    # * The below code was intended to shorten the list of circles in order to 
    # improve efficiency, however it had an error due to the index provided by
    # "wark[0]" being incorrect after the element in the previous iteration 
    # was deleted... *
    ## Remove the marks that were assigned to a robot- this will potentially make 
    ## assigning the rest of the marks much quicker with larger numbers of robots
    #for wark in closestMarks:
    #    del roboIDmarks[wark[0]]
    #else:
    #    print("No robots detected, but there are ID marks..?")

# RoboID()
# E.H., Jan, 2019
# This function reads the sorted robot.circles list and assigns an ID (robot.ID = x)
# to the robot. If the IDs are not properly sorted, this will not work
# v2:
# Has all IDs implemented
def RoboID(robot):
    #for robot in roboList:
    #print('team')
    #print(robot.team)
    if len(robot.circles) == 4:
        #print(robot.circles)
        if robot.team == 'B':
            if robot.circles[0][2] == 'P': # circle 1
                if robot.circles[1][2] == 'P': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 10
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 5
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 1
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 11
                elif robot.circles[1][2] == 'G': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 8
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 4
            elif robot.circles[0][2] == 'G': # circle 1
                if robot.circles[1][2] == 'P': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 6
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 2
                elif robot.circles[1][2] == 'G': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 12
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 7
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 3
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 9
        elif robot.team == 'Y':
            if robot.circles[0][2] == 'P': # circle 1
                if robot.circles[1][2] == 'P': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 26
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 21
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 17
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 27
                elif robot.circles[1][2] == 'G': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 24
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 20
            elif robot.circles[0][2] == 'G': # circle 1
                if robot.circles[1][2] == 'P': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 22
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 18
                elif robot.circles[1][2] == 'G': # circle 2
                    if robot.circles[2][2] == 'P': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 28
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 23
                    elif robot.circles[2][2] == 'G': # circle 3
                        if robot.circles[3][2] == 'P': # circle 4
                            robot.ID = 19
                        elif robot.circles[3][2] == 'G': # circle 4
                            robot.ID = 25
    #print(robot.ID)


# angle()
# E.H., Jan, 2019
# This function determines the angle of a passed robot using the IDs assigned to the robot
# by observing relative positions of said IDs. The angle determined is assigned to the robot
# at the end of the function, and reassignIDs() is called at the end to allow for identification
# of the robot.
#              (input) -> (function) -> (output)
#               ID marks -> angle() -> robot.angle
def angle(robot):	
    topIDs = [] # i.e. the two circles on the flat end of the robot
    bottomIDs = []
    theta1 = 999 # An impossible number for if statements later
    theta2 = 999

    # Uses the cosine law to figure out the angle every possible combo of ID circles makes
    # with the center of the robot (team ID), assigning to top or bottom IDs based on this angle
    for ii in range(len(robot.circles)-1):
        for jj in range(ii + 1, len(robot.circles)):
            temp1 = robot.circles[ii]
            temp2 = robot.circles[jj]

            # Determining distance between the different IDs
            a = dist.euclidean([temp1[0],temp1[1]],robot.pos) # Distance from ID 1 to centre
            b = dist.euclidean([temp2[0],temp2[1]],robot.pos) # Distance from ID 2 to centre
            c = dist.euclidean([temp1[0],temp1[1]],[temp2[0],temp2[1]]) # Distance from ID 1 to ID 2
            try:
                theta = math.degrees(math.acos((c**2 - b**2 - a**2)/(-2.0 * a * b))) #CRASHES ON RARE OCCASIONS
            except:
                print('Theta Error')
            if theta > 100 and theta < 130: # Ideally 114.84 degrees
                topIDs.append(temp1)
                topIDs.append(temp2)
                     
            if theta > 55 and theta < 75: # Ideally 65.16 degrees
                bottomIDs.append(temp1)
                bottomIDs.append(temp2)

            # the other ID pairs will be either ~180 or ~90 degrees

    # Takes the top two IDs and their average position, creating a vector to that point from the
    # center of the robot which the robot's angle can be derived from
    if len(topIDs) == 2:
        xMean = (topIDs[0][0] + topIDs[1][0])/2
        yMean = (topIDs[0][1] + topIDs[1][1])/2

        xDiff = xMean - robot.pos[0]
        yDiff = yMean - robot.pos[1]
        # Angle points in the direction the robot is facing
        theta1 = math.degrees(math.atan2(yDiff,xDiff))
    #else:
        #print("top went wrong...")
        
    # Takes the bottom two IDs and their average position, creating a vector from that point to
    # the center of the robot which the robot's angle can be derived from
    # (this is the opposite direction from the other one so the angle will be the same)
    if len(bottomIDs) == 2:
        xMean2 = (bottomIDs[0][0] + bottomIDs[1][0])/2
        yMean2 = (bottomIDs[0][1] + bottomIDs[1][1])/2

        xDiff2 = robot.pos[0] - xMean2
        yDiff2 = robot.pos[1] - yMean2
        # Negative for both of these to get an angle that is front facing
        theta2 = math.degrees(math.atan2(yDiff2,xDiff2))
    #else:
    #    print("bottom is wrong")

    # Averages the vectors to get a better approx of the true angle
    if theta2 != 999 and theta1 != 999:
        xMean = (math.cos(math.radians(theta1)) + math.cos(math.radians(theta2)))/2
        yMean = (math.sin(math.radians(theta1)) + math.sin(math.radians(theta2)))/2
        theta = math.degrees(math.atan2(yMean,xMean))
        robot.angle = theta

    # If one of the vector calcs failed, just take the one that worked
    elif theta2 != 999 and theta1 == 999:
        theta = theta2
        robot.angle = theta
        print('THETA1ERROR')
    elif theta2 == 999 and theta1 != 999:
        theta = theta1
        robot.angle = theta
        print('THETA2ERROR')
    else:
        return "ERROR"

    reassignIDs(robot,topIDs,bottomIDs)

# reassignIDs()
# E.H., Jan, 2019
# This function reassigns the IDs found in a robot depending on the angle the robot
# is facing. It is helpful to draw out a visualization of this to understand why 
# certain angles are associated with certain indices in robot.circles
#              (input) -> (function) -> (output)
#              angle -> reassignIDs() -> robot.circles (sorted)
def reassignIDs(robot,topIDs,bottomIDs):
    # Reassignment of IDs only works if all four have been recognized
    if len(robot.circles) == 4 and len(topIDs) == 2 and len(bottomIDs) == 2:
        # I suggest drawing this out if you're having a hard time visualizing it-
        # see the design document for further detail on which ID is which
        if robot.angle <= 45 and robot.angle >= -45:
            if topIDs[0][1] > topIDs[1][1]:
                robot.circles[0] = topIDs[1]
                robot.circles[1] = topIDs[0]
            else:
                robot.circles[0] = topIDs[0]
                robot.circles[1] = topIDs[1]
            if bottomIDs[0][1] > bottomIDs[1][1]:
                robot.circles[2] = bottomIDs[1]
                robot.circles[3] = bottomIDs[0]
            else:
                robot.circles[2] = bottomIDs[0]
                robot.circles[3] = bottomIDs[1]
        if robot.angle < 135 and robot.angle > 45:
            if topIDs[0][0] > topIDs[1][0]:
                robot.circles[0] = topIDs[0]
                robot.circles[1] = topIDs[1]
            else:
                robot.circles[0] = topIDs[1]
                robot.circles[1] = topIDs[0]
            if bottomIDs[0][0] > bottomIDs[1][0]:
                robot.circles[2] = bottomIDs[0]
                robot.circles[3] = bottomIDs[1]
            else:
                robot.circles[2] = bottomIDs[1]
                robot.circles[3] = bottomIDs[0]
        if robot.angle < -45 and robot.angle > -135:
            if topIDs[0][0] > topIDs[1][0]:
                robot.circles[0] = topIDs[1]
                robot.circles[1] = topIDs[0]
            else:
                robot.circles[0] = topIDs[0]
                robot.circles[1] = topIDs[1]
            if bottomIDs[0][0] > bottomIDs[1][0]:
                robot.circles[2] = bottomIDs[1]
                robot.circles[3] = bottomIDs[0]
            else:
                robot.circles[2] = bottomIDs[0]
                robot.circles[3] = bottomIDs[1]
        if robot.angle <= -135 or robot.angle >= 135:  # must be "or", as sign swaps at 180
            if topIDs[0][1] > topIDs[1][1]:
                robot.circles[0] = topIDs[0]
                robot.circles[1] = topIDs[1]
            else:
                robot.circles[0] = topIDs[1]
                robot.circles[1] = topIDs[0]
            if bottomIDs[0][1] > bottomIDs[1][1]:
                robot.circles[2] = bottomIDs[0]
                robot.circles[3] = bottomIDs[1]
            else:
                robot.circles[2] = bottomIDs[1]
                robot.circles[3] = bottomIDs[0]
    return

# stoprobot()
# E.H., Mar, 2019
# This function will stop any robots passed into it by issuing stop commands to 
# the specified robot. Alternatively, if 'all' is passed in, it will stop all robots.
def stoprobot(ID):
    packet = bytearray()
    if(ID == 'all'): # Send stop commands to all robots
        print("stopping robots")
        for robot in range(0,12):
            packet.append(0xFF) # start bit
            packet.append(robot)  #Robot ID
            packet.append(1)
            packet.append(0)
            packet.append(1)
            packet.append(0)
            packet.append(0)
            packet.append(0xFF) # stop bit
            KL25.write(packet)
            packet = bytearray()
    elif(ID >= 0 and ID <= 11): # Only accept valid IDs
        packet.append(0xFF) # start bit
        packet.append(ID)  #Robot ID
        packet.append(1)
        packet.append(0)
        packet.append(1)
        packet.append(0)
        packet.append(0)
        packet.append(0xFF) # stop bit
        KL25.write(packet)


def goalieMode(ball_location):

    #Global
    lengthgoalie = 5
    global xgoalie
    global ygoalie
    global goalie_index
    #Test
    endlocation = 0
    angle_new = 0
    ballpos = ball_location

    #Test PD
    #xgoalie = np.arange(80,100,1)
    #ygoalie = np.arange(120,140,1)

    if ball != None and ballpos[0]!=0:
        x=ballpos[0]
        y=440
        #Find Array

        if goalie_index<lengthgoalie:
            xgoalie.append(ballpos[0])
            ygoalie.append(ballpos[1])
            goalie_index=goalie_index+1
        else:
            xgoalie.pop(0)
            xgoalie.append(ballpos[0])
            ygoalie.pop(0)
            ygoalie.append(ballpos[1])

        #Find the x derivative

        print( "x" ,xgoalie, )
        print( "y" ,ygoalie, )
        dx_dy = np.diff(xgoalie)/np.diff(ygoalie)
        sumg = sum(dx_dy)
        der = sumg / (lengthgoalie-1)

        if np.isnan(der) or np.isinf(der):
            der=0

        print(der,'der')
        x = (der*440) + (ballpos[0] - (der*ballpos[1]))

        print("before change:" ,x, )

        #Find angle
        thetarad = np.arctan(der)
        thetadeg = (thetarad*180)/3.14159
        angle_new = -90 - thetadeg


        if x < 220:
            x=220
            angle_new = 180
        elif x > 420:
            x=420
            angle_new = 180
        endlocation = np.array([x, y])
    else: 
        endlocation = np.array([320, 440])
        angle_new = 180

    return endlocation
    
    print(" after change: " ,endlocation, )
    print(" Angle: " ,angle_new, )
    print( "x" ,xgoalie, )
    print( "y" ,ygoalie, )
    print(" dxdy: ",dx_dy, )
    print(" sum: ",sumg, )
    print(" derivative: ",der)
    print(" degree: ",thetadeg)




def shotcost(pos,eposx,eposy,aposx,aposy,net,res):#Cost function for shooting at the net

    maxdis=np.sqrt(res[0]**2+res[1]**2)#Calculating maximun distance

    dis=np.sqrt((pos[0]-net[0])**2+(pos[1]-net[1])**2)#Calculating distance from net

    p=1-0.5*dis/maxdis#Probability of scoring based on distance

    x=np.linspace(pos[0],net[0],30)
    y=np.linspace(pos[1],net[1],30)

    for ii in range(len(eposx)):#Probability of scoring based on enemy robots
        minde=np.min(np.sqrt((x-eposx[ii])**2+(y-eposy[ii])**2))
        factor=1-2500/(minde)**2

        if factor<0:
            factor=0
        p=p*factor

    for ii in range(len(eposx)):#Probability of scoring based on ally robots
        minde=np.sqrt((pos[0]-eposx[ii])**2+(pos[1]-eposy[ii])**2)
        factor=1-2500/(minde)**2

        if factor<0:
            factor=0
        p=p*factor

    dif=net-pos
    angle=np.abs(np.arctan(dif[1]/dif[0]))*180/3.1415;
    factorangle=1-angle/90;#Probability of scoring based on angle from net

    p=p*factorangle;
    return p

def passcost(startpos,endpos,eposx,eposy,aposx,aposy,res):#Not used currently but is implemented in the matlab code

    maxdis=np.sqrt(res[0]**2+res[1]**2)#Max distance

    dis=np.sqrt((startpos[0]-endpos[0])**2+(startpos[1]-endpos[1])**2) #Distance of pass

    p=1-0.4*dis/maxdis;#Probability of makoing the pass

    x=np.linspace(startpos[0],endpos[0],30);
    y=np.linspace(startpos[1],endpos[1],30);

    for ii in range(len(eposx)):#Probability of making the pass based on enemy robots
        minde=np.min(np.sqrt((x-eposx[ii])**2+(y-eposy[ii])**2))
        factor=1-2500/(minde)**2

        if factor<0:
            factor=0
        p=p*factor

    for ii in range(len(aposx)):#Probability of making the pass based on ally robots
        minda=np.min(np.sqrt((x-aposx[ii])**2+(y-aposy[ii])**2))
        factor=1-2500/(minda)**2

        if factor<0:
            factor=0
        p=p*factor

    return p

def pathcost(pos,eposx,eposy,aposx,aposy):#Cost function of the path you take, prevents the path from going through another robot

    p=1
    for ii in range(len(aposx)):#Probability of scoring based on the enemy robots positions
        minda=np.sqrt((pos[0]-aposx[ii])**2+(pos[1]-aposy[ii])**2)
        factor=1-2500/(minda)**2
        factor=factor
        if factor<0:
            factor=0
        p=p*factor

    for ii in range(len(eposx)):#Probability of scoring based on the ally robots positions
        minde=np.min(np.sqrt((pos[0]-eposx[ii])**2+(pos[1]-eposy[ii])**2))
        factor=1-2500/(minde)**2
        factor=factor
        if factor<0:
            factor=0
        p=p*factor

    return p

def timestep(nstep,maxmove,eposx,eposy,aposx,aposy,tsreduc,passreduc,parr,punisharray,net,res,count):#Timme iterations function
    
    for ll in range(count,len(nstep),1):
        if count>0:
            pos=np.array(nstep[ll][-1])
        else:
            pos=nstep[ll]
        newposx=[];
        newposy=[];
        anewposx=[];
        anewposy=[];
        for ii in range(-maxmove,maxmove+1,maxmove):#Defining all future positions
            for jj in range(-maxmove,maxmove+1,maxmove):
                xposnew=pos[0]+jj
                yposnew=pos[1]+ii
                if xposnew>0 and xposnew<res[0] and yposnew>0 and yposnew<res[1] and (jj!=0 or ii!=0):
                    newposx.append(xposnew)
                    newposy.append(yposnew)

        for kk in range(0,len(newposx),1):#Calcuting the probability of scoring for each posibility
            parr.append(shotcost(np.array([newposx[kk], newposy[kk]]),eposx,eposy,aposx,aposy,net,res)*tsreduc*punisharray[ll])

            t1=nstep[ll]
            t2=np.array([newposx[kk], newposy[kk]])
            t3=np.vstack((t1,t2))
            nstep.append(t3)

            punisharray.append(punisharray[ll]*tsreduc*pathcost(np.array([newposx[kk], newposy[kk]]),eposx,eposy,aposx,aposy))

    count=ll+1;
    return parr,nstep,punisharray,count


def aicontrol(ID,net,res):#Markov Algorithm

    global roboList

    action='none'

    xrobloc=[]
    yrobloc=[]
    for rob in roboList:#Finding all robots on the feild
        if (rob.ID != 0) & (isinstance(roboList, type(None)) == 0):
            if rob.ID==ID:
                start=rob.pos
            else:
                xrobloc.append(rob.pos[0])
                yrobloc.append(rob.pos[1])

    np.array(xrobloc)
    np.array(yrobloc)

    maxmove=60#Max distance you can travel in 1 time iteration
    tsreduc=0.8#Punishment for each time iteration
    passreduc=1#Punishment for a pass
    parr=[shotcost(start,xrobloc,yrobloc,[],[],net,res)]#array holding at probailities of scoring
    nstep=[start]#Array holding at paths taken
    punisharray=[1]#Arraying holding at punishments such as passing, time iteration,etc
    count=0

    parr,nstep,punisharray,count=timestep(nstep,maxmove,xrobloc,yrobloc,[],[],tsreduc,passreduc,parr,punisharray,net,res,count)#Time iterations
    parr,nstep,punisharray,count=timestep(nstep,maxmove,xrobloc,yrobloc,[],[],tsreduc,passreduc,parr,punisharray,net,res,count)
    #parr,nstep,punisharray,count=timestep(nstep,maxmove,xrobloc,yrobloc,[],[],tsreduc,passreduc,parr,punisharray,net,res,count)

    I=np.argmax(parr)#Best path
    bestpos=nstep[I]

    if (I==0):
        endloc=start
        action='shoot'
    else:
        endloc=bestpos[1]

    return endloc,action

def create_circle_points(loc,rad,num):#Creating circles aroud a given point for the path planning
    
    angle=np.linspace(0,2*3.1415,num)
    x=[]
    y=[]
    for ii in range(len(angle)):
        x.append(rad*math.cos(angle[ii])+loc[0])
        y.append(rad*math.sin(angle[ii])+loc[1])
    x=np.array(x)
    y=np.array(y)

    x = x[:, np.newaxis]
    y = y[:, np.newaxis]

    z = np.float32(np.concatenate((x,y), axis=1))
    return z



def splinePaths(ID, endloc, resolution, action):#Path planning

    global roboList

    rflag=0
    count=0
    xrobloc=[]
    yrobloc=[]
    #robloc=[]
    for rob in roboList:#Finding all robots on the field
        if (rob.ID != 0) & (isinstance(roboList, type(None)) == 0):
            count=count+1
            if rob.ID==ID:
                start=rob.pos
            else:
                #robloc=rob.pos
                rflag=1
                xrobloc.append(rob.pos[0])
                yrobloc.append(rob.pos[1])

    resolution = float(resolution)
    l = np.sqrt((start[0]-endloc[0])**2+(start[1]-endloc[1])**2)                               # length of point sequence
    nSamples = int(l/resolution)                 # number of samples

    if nSamples<20:
        nSamples=20

    xnew = np.linspace(start[0], endloc[0], num=nSamples, endpoint=True)
    ynew = np.linspace(start[1], endloc[1], num=nSamples, endpoint=True)
    if count < 2 or rflag==0 or action=='shoot': #If there are less than 2 robots return a linear path
        xnew = xnew[:, np.newaxis]
        ynew = ynew[:, np.newaxis]
        samples = np.float32(np.concatenate((xnew,ynew), axis=1))
        return samples

    rad=100#Radius of circles drawn
    num=50#Number of circles drawn

    arcfinal=100000
    index=0
    samplesfinal=0
    mind=75#Minimun disatance paths must be from another robot
    ud=1000;
    udcuttoff=75#cut of distance endpoint or initial robot must be from another robot else it returns a linear path

    ll=0
    while ll < len(xrobloc):
        dist=np.sqrt((endloc[0]-xrobloc[ll])**2 + (endloc[1]-yrobloc[ll])**2)
        if dist<mind:
            xrobloc.pop(ll)
            yrobloc.pop(ll)
            ll=ll-1
        ll=ll+1

    temp=[]
    for kk in range(len(xrobloc)):
        temp.append(create_circle_points([xrobloc[kk], yrobloc[kk]],rad,num))

    entered=0
    dflag=0
    dflag2=0
    p=[]
    for kk in range(len(xrobloc)): 
        dflag=0
        for jj in range(len(xnew)):
            ud=np.sqrt((xnew[jj]-xrobloc[kk])**2 + (ynew[jj]-yrobloc[kk])**2)
            #print(ud)
            if ud<udcuttoff:
                dflag=1
                dflag2=1
        if dflag==1:
            p.append(temp[kk])

    if dflag2==1:
        for ii in range(num):
            ptempx=[]
            ptempy=[]
            for kk in range(len(p)):
                ptempx.append(p[kk][ii,0])
                ptempy.append(p[kk][ii,1])

            ptempx.insert(0,start[0])
            ptempx.append(endloc[0])
            xt=ptempx
            ptempy.insert(0,start[1])
            ptempy.append(endloc[1])
            yt=ptempy

            
            if len(xt)>3:#Creating splines
                path = interp1d(xt, yt, kind='cubic')
            else:
                path = interp1d(xt, yt, kind='quadratic')
            
            samples=path(xnew)

            eucd=100000
            for kk in range(len(temp)):#Finding the mininum distance from other robots
                etemp=np.min(np.sqrt((xnew-xrobloc[kk])**2 + (samples-yrobloc[kk])**2))
                if etemp<eucd:
                    eucd=etemp

            #plt.plot(xt, yt, 'o', xnew, samples, '-')

            dif=np.diff(xnew)#Calculating the arc length of the paths
            der=np.diff(samples)/dif;
            arc=abs(np.sum(np.sqrt(1+der**2)*dif))
            if arc<arcfinal and eucd>mind:#Checking if the path is too close to another robot
                entered=1;
                arcfinal=arc
                index=ii
                samplesfinal=samples
            
    else:
        samplesfinal=ynew

    if (entered==0):
        samplesfinal=ynew

    #print(samplesfinal,'samplesfinal')
    xnew = xnew[:, np.newaxis]
    samplesfinal = samplesfinal[:, np.newaxis]
    samples = np.float32(np.concatenate((xnew,samplesfinal), axis=1))
    return samples#Returning the best path

def sampleCubicSplinesWithDerivative(points, tangents, resolution):
    '''
    Compute and sample the cubic splines for a set of input points with
    optional information about the tangent (direction AND magnitude). The 
    splines are parametrized along the traverse line (piecewise linear), with
    the resolution being the step size of the parametrization parameter.
    The resulting samples have NOT an equidistant spacing.
    Arguments:      points: a list of n-dimensional points
                    tangents: a list of tangents
                    resolution: parametrization step size
    Returns:        samples
    Notes: Lists points and tangents must have equal length. In case a tangent
           is not specified for a point, just pass None. For example:
                    points = [[0,0], [1,1], [2,0]]
                    tangents = [[1,1], None, [1,-1]]
    '''
    resolution = float(resolution)
    points = np.asarray(points)
    nPoints, dim = points.shape

    # Parametrization parameter s.
    dp = np.diff(points, axis=0)                 # difference between points
    dp = np.linalg.norm(dp, axis=1)              # distance between points
    d = np.cumsum(dp)                            # cumsum along the segments
    d = np.hstack([[0],d])                       # add distance from first point
    l = d[-1]                                    # length of point sequence
    nSamples = int(l/resolution)                 # number of samples
    s,r = np.linspace(0,l,nSamples,retstep=True) # sample parameter and step

    # Bring points and (optional) tangent information into correct format.
    assert(len(points) == len(tangents))
    data = np.empty([nPoints, dim], dtype=object)
    for i,p in enumerate(points):
        t = tangents[i]
        # Either tangent is None or has the same
        # number of dimensions as the point p.
        assert(t is None or len(t)==dim)
        fuse = list(zip(p,t) if t is not None else zip(p,))
        data[i,:] = fuse

    # Compute splines per dimension separately.
    samples = np.zeros([nSamples, dim])
    for i in range(dim):
        poly = interpolate.BPoly.from_derivatives(d, data[:,i])
        samples[:,i] = poly(s)
    return samples

# Feedback Linearization (Koceila's) global variables:
init_rob_x = 0
init_rob_y = 0
init_rob_angle =0

# Path Planning (Mike's) global variables:
points = []
tangents = []
samples_prev = []
next_point_x = 0
next_point_y = 0

# Kalman Filter (Yan's) global variables:
###
#Mathematical model of a moving mass
	#this kalman filter regulate on a x-y axis
	#This Kalman Filter filters out measurement noise and gives best estimate of where the robot is. 
## The dt variable should be variable based on the number of frame rates obtained by the CV system. 
####### This frame rate should be calculated. #########
dt=1/10    
Fx = np.matrix([[1,dt], [0,1]])#A Matrix (state transfer function)(x direction) 
Bx=np.matrix([[dt**2/2], [dt]]) #B Matrix (control function)(x direction)
Xx=np.matrix([[0],[0]])#initial state(belief values) (doesn't matter what it is.)(x direction)
print("Xx belief",Xx)
Fy = np.matrix([[1,dt], [0,1]])#A Matrix (state transfer function)(y direction) 
By=np.matrix([[dt**2/2], [dt]]) #B Matrix (control function)(y direction)
Xy=np.matrix([[0],[0]])#initial state(belief values) (doesn't matter what it is.)(y direction)
mu, sigma = 0, 5
noisex=random.gauss(mu, sigma)#noise of pos from measurement (should be 1*1) assuming gaussian white noise with mean = 0 and variance of 5(fairly certain on the measurement data)
noisey=noisex
#noise = randn(1)
Px=np.matrix([[1,0],[0,1]])#state covariance matrix (doesn't matter what it is at the start as it will be iterated.)
Qx=np.matrix([[0.01,0],[0 ,0.01]])#state predicted noise (when state transformation happens q(k) is process noise and covariance matrix is Q)
Hx=np.matrix([[1,0]])#observation matrix (only pos is observable, vel is not)
Rx=1#observation noise covariance 
	
Py=np.matrix([[1,0],[0,1]])#state covariance matrix (doesn't matter what it is at the start as it will be iterated.)
Qy=np.matrix([[0.01,0],[0 ,0.01]])#state predicted noise (when state transformation happens q(k) is process noise and covariance matrix is Q)
Hy=np.matrix([[1,0]])#observation matrix (only pos is observable, vel is not)
Ry=1#observation noise covariance 
	
#Mathematical model of a rotating mass
#This Kalman Filter filters out measurement noise and gives best estimate of where the robot is oriented. It is done in 1-d.
F_angle = np.matrix([[1,dt], [0,1]])#A Matrix (state transfer function) 
B_angle=np.matrix([[dt**2/2], [dt]]) #B Matrix (control function)
X_angle=np.matrix([0,0])#initial state(belief values) (doesn't matter what it is.)
mu, sigma = 0, 5
noise=random.gauss(mu, sigma)#noise of angle from measurement (should be 1*1) assuming gaussian white noise with mean = 0 and variance of 10 degrees
P_angle=np.matrix([[1,0],[0,1]])#state covariance matrix (doesn't matter what it is at the start as it will be iterated.)
Q_angle=np.matrix([[1,0],[0 ,1]])#state predicted noise (when state transformation happens q(k) is process noise and covariance matrix is Q)
H_angle=np.matrix([[1,0]])#observation matrix (only pos is observable, vel is not)
R_angle=0.01#observation noise covariance 

temp_u1=0
temp_u2=0

###

## PD controller Parametters
error1=0
error_prior1=0
error2=0
error_prior2=0
         
derivative1=0       
L=18                #Robot Diameter
R=3.5               #Wheel Radius
dirR=0
dirL=0
umax=575            #Max input for position control
u2max= 220
kp1= 1.65 #was 0.65
kp2=1.5#was 1.2, 0.01
kp = 1.5                                        # same as below
flag =  0
kd1=0.5#was 0.5
kd2=0.5 #was 0.005
kd = 0.5                                          # fix this <<<<< (need to make it used)
VrMax = 1000
VlMax = VrMax 
temp1=0
temp2=0
test = 0
counter = 0
kickcounter=0

# flag for switching mains
radioflag = 0
# flag for path planning
attacker_defender_flag = 0

# record data flag
recordFlag = 0

cap = cv2.VideoCapture(cv2.CAP_DSHOW + 0) # 0 if your pc doesn't have a webcam, probably 1 if it does

# Plot Lists
Desired_X = []
Actual_X = []
Desired_Y = []
Actual_Y = []
Desired_Angle = []
Actual_Angle = []

#Inputs 
Input_V= []
Input_W= []

angle_meas_list=[]
angle_bel_list=[]
angle_predicted_list=[]

angleRecording = []
posRecording = [[],[]]

startTime = timer()
endTime = 0
mainLoopTime = []

intergral=0

def mainLoop():

    global startTime, endTime, mainLoopTime
    if(recordFlag == 1):
        endTime = timer()
        mainLoopTime.append(endTime-startTime)
        startTime = timer()
    print("new loop normal\n\r")
    # Declaring global variables so they can be cleared every loop
    global roboList, roboListGUI, roboIDmarks, circles, ball, ballGUI, IDdRobots

    global error1,error_prior1,error2,error_prior2,dt,derivative1,L,R,dirR,dirL,umax,u2max,kp1
    global kp2,flag,kd1,kd2,VrMax,VlMax,temp1,temp2,test,counter
    global Desired_X, Actual_X, Desired_Y, Actual_Y, Desired_Angle, Actual_Angle
    
    global angleRecording, posRecording

    #cap = cv2.VideoCapture(cv2.CAP_DSHOW + 0) # 0 if your pc doesn't have a webcam, probably 1 if it does
    # https://stackoverflow.com/questions/52043671/opencv-capturing-imagem-with-black-side-bars
    # MSMF doesn't like being scaled up apparently, so switch from it (default) to DirectShow
    # so we can scale up the resolution read from the camera

    # Scaling up from 640x480 to HD 1280x720
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    


    #while(True):
    #  while(KL25.inWaiting()==0):
  
    ret,frame = cap.read() # reading the video capture into a dummy var and frame

    #cv2.waitKey(50)
        
    # Reinitializing robot data (prevents buildup of data accross frames)
    roboList = []
    roboIDmarks= []
    circles = []
    ball = None

    # Histogram equalization for colors (haven't tested with this)
    #img_yuv = cv2.cvtColor(ii, cv2.COLOR_BGR2YUV)

    ### equalize the histogram of the Y channel
    #img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])

    ### convert the YUV image back to RGB format
    #frame_yuv = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

    # blurring image for less errant circles and better color recognition later
    # d = 5 as that is the recommended nearest neighbour for real time
    # sigmaColor = 150 to produce large blending effect
    # sigmaSpace is limited by d, so I suspect it doesn't matter
    blurred_img = cv2.bilateralFilter(frame,8,150,150) 
    
    # HSV color space conversion
    hsv= cv2.cvtColor(blurred_img,cv2.COLOR_BGR2HSV)
    #rgb= cv2.cvtColor(blurred_img,cv2.COLOR_BGR2GRAY)
   
    # Color masking, not necessary due to blurring, but might be worth looking into further
    #lower_rangeG = np.array([0,0,0]) # Hue, Saturation, Value mask lower limit
    #upper_rangeG = np.array([180,255,255]) # " , " , " " upper limit

    #mask = cv2.inRange(hsv, lower_rangeG, upper_rangeG) # mask for original frame with only good color
    #result = cv2.bitwise_and(blurred_img,blurred_img,mask=mask)
    result = blurred_img
    
    #cv2.imshow("blurred image",result)
  
    hsv_out_gray= cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
    #rgb_out_gray= cv2.cvtColor(result, cv2.COLOR_BGR2HSV)
    
    #cv2.imshow("houghin",hsv_out_gray)

    # Some notes on the HoughCircles function:
    #  Utilizes edge detection to draw tangent lines, recognizing a circle where perpendicular lines to tangents
    #  meet, depending on the intensity of the intersecting tangent lines.
    #  param1: higher threshold for Canny edge detection (lower is half of this)
    #  param2: accumulator threshold for circle center detection- i.e. the lower it is, the less circular an object
    #          needs to be to be recognized as a circle
    #  minDist: Specifies minimum distance between circles (the 4th input to the function)
    #  
    # from documentation: cv2.HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) â†’ circles
    circles = cv2.HoughCircles(hsv_out_gray,cv2.HOUGH_GRADIENT,1,minDist=5,param1=param1val,param2=param2val,minRadius=1,maxRadius=20)
    #circles = cv2.HoughCircles(result,cv2.HOUGH_GRADIENT,1,minDist=5,param1=param1val,param2=param2val,minRadius=1,maxRadius=20)
    
    cv2.waitKey(1) # cv2.waitKey() is required to display images- waits 1 millisecond here

    img = copy.deepcopy(frame) # Sometimes if you copy stuff in Python, changes made to a copied variable end up in original
                                # which necessitates a deepcopy
    
    if isinstance(circles, type(None)) == 0:
        for circle in circles[0,:]:
            IDcircle(hsv, circle) # ID all the circles recognized by color
            # draw the outer circle
            cv2.circle(img,(circle[0],circle[1]),circle[2],(0,255,0),2)
            # draw the center of the circle
            cv2.circle(img,(circle[0],circle[1]),2,(0,0,255),3)
        if isinstance(ball, type(None)) == 0:
            # Draw a blue circle on the ball
            cv2.circle(img,(ball.pos[0],ball.pos[1]),10,(200,0,0),5)  
            cv2.putText(img, str(ball.pos), (ball.pos[0]+20,ball.pos[1]+20), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
        if (isinstance(roboIDmarks, type(None)) == 0) & (isinstance(roboList, type(None)) == 0):
            for robot in roboList:
                assignIDmarks(robot) # Assign the ID marks observed to their appropriate robot
                angle(robot)         # Determine angle of robots seen
                RoboID(robot)        # Give robots seen an ID

                # Draw the robot circles seen robot by robot
                # Draw a black circle on the centre of the robot
                cv2.circle(img,(robot.pos[0],robot.pos[1]),5,(0,0,0),2)
                #if isinstance(robot.angle, type(None)) == 0:
                #    # Display the robot's angle
                #    cv2.putText(img, str(round(robot.angle,1)), (robot.pos[0]+ 100, robot.pos[1] + 130), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's position
                #    cv2.putText(img, str(robot.pos), (robot.pos[0]+ 100, robot.pos[1] + 100), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's ID
                #    cv2.putText(img, robot.ID, (robot.pos[0]+ 100, robot.pos[1] + 70), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's Team
                #    cv2.putText(img, robot.team, (robot.pos[0]+ 100, robot.pos[1] + 40), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                for mark in robot.circles:
                    # Draw a black circle on every ID mark
                    cv2.circle(img,(mark[0],mark[1]),5,(0,0,0),2)  
        flag = 0 # go ahead and print "no circles detected" again

    elif(flag == 0):
        #print("no circles detected")
        flag = 1 # don't print this again

    # Display drawn on frame and original frame
    #cv2.imshow('circles on stream',img)
    #cv2.imshow('original stream',frame)

    #if cv2.waitKey(1) & 0xFF == ord('\r'): # if enter is pressed, stop running
    #    break

    # when the ball does not get detected
    if (isinstance(ball, type(None)) != 0):
        ball = ballClass(temp1,temp2)  

    if(recordFlag == 1):
        print("recording roboList stuff")
        angleRecording.append(roboList[0].angle)
        posRecording[0].append(roboList[0].pos[0])
        posRecording[1].append(roboList[0].pos[1])
        
    packet = bytearray()

    # GUI Stuff
    id=[]
    flag=1;
    for rob in roboList:
        if (rob.ID != 0) & (isinstance(roboList, type(None)) == 0):
            flag=0;

    roboListGUI=[]
    roboListGUI=roboList

    ballGUI=ball
    if flag==0:
        #print('ENTER CHECK')
        widget.updategui()
        widget.show()

    # ********************************************************************************************************
    for rob in roboList:
        if (rob.ID != 0) & (isinstance(roboList, type(None)) == 0):
            if(abs(abs(rob.angle)-180)>20 and counter>5):
                   if (abs(rob.angle-test) >=200 and counter > 5):
                      rob.angle=test#something is wrong with the angle measurement
                      print('ANGLE ERROR')
                    
            else:
                   
                if (abs(abs( rob.angle)-abs(test)) >=50 and counter>5 ):
                    rob.angle=test#something is wrong with the angle measurement
                    print('ANGLE ERROR 2')
            test=rob.angle

            #print("rob.angle",rob.angle)
            # Display the robot's angle
            cv2.putText(img, str(round(rob.angle,1)), (rob.pos[0]+ 50, rob.pos[1] + 130), 
                        cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
            # Display the robot's position
            cv2.putText(img, str(rob.pos), (rob.pos[0]+ 50, rob.pos[1] + 100), 
                        cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
            # Display the robot's ID
            cv2.putText(img, 'ID'+str(rob.ID), (rob.pos[0]+ 50, rob.pos[1] + 70), 
                        cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
            # Display the robot's Team
            cv2.putText(img, rob.team, (rob.pos[0]+ 50, rob.pos[1] + 40), 
                        cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

    cv2.imshow('circles on stream',img)


#Goalie Mode
def mainLoop4():
    print("new loop path planning\n\r")
    # Declaring global variables so they can be cleared every loop
    global roboList, roboIDmarks, circles, ball, IDdRobots, ball_possesor_id

    global error1,error_prior1,error2,error_prior2,dt,derivative1,L,R,dirR,dirL,umax,u2max,kp1
    global kp2,flag,kd1,kd2,VrMax,VlMax,temp1,temp2,test,counter,ki

    #Mikes Global Variables
    global points
    global tangents
    global samples_prev
    global next_point_x, next_point_y
    global intergral
    global kickcounter
    global goalie_flag
   
    #cap = cv2.VideoCapture(cv2.CAP_DSHOW + 0) # 0 if your pc doesn't have a webcam, probably 1 if it does
    # https://stackoverflow.com/questions/52043671/opencv-capturing-imagem-with-black-side-bars
    # MSMF doesn't like being scaled up apparently, so switch from it (default) to DirectShow
    # so we can scale up the resolution read from the camera

    # Scaling up from 640x480 to HD 1280x720
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    

    #while(True):
    #  while(KL25.inWaiting()==0):

    ret,frame = cap.read() # reading the video capture into a dummy var and frame

    #cv2.waitKey(50)
        
    # Reinitializing robot data (prevents buildup of data accross frames)
    roboList = []
    roboIDmarks= []
    circles = []
    ball = None

    #Mike's Added Value Parameters
    points = []
    tangents = []
    resolution = 0.2 #was 0.2

    # Histogram equalization for colors (haven't tested with this)
    #img_yuv = cv2.cvtColor(ii, cv2.COLOR_BGR2YUV)

    ### equalize the histogram of the Y channel
    #img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])

    ### convert the YUV image back to RGB format
    #frame_yuv = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

    # blurring image for less errant circles and better color recognition later
    # d = 5 as that is the recommended nearest neighbour for real time
    # sigmaColor = 150 to produce large blending effect
    # sigmaSpace is limited by d, so I suspect it doesn't matter
    blurred_img = cv2.bilateralFilter(frame,8,150,150) 

    # HSV color space conversion
    hsv= cv2.cvtColor(blurred_img,cv2.COLOR_BGR2HSV)

    # Color masking, not necessary due to blurring, but might be worth looking into further
    #lower_rangeG = np.array([0,0,0]) # Hue, Saturation, Value mask lower limit
    #upper_rangeG = np.array([180,255,255]) # " , " , " " upper limit

    #mask = cv2.inRange(hsv, lower_rangeG, upper_rangeG) # mask for original frame with only good color
    #result = cv2.bitwise_and(blurred_img,blurred_img,mask=mask)
    result = blurred_img

    #cv2.imshow("blurred image",result)
  
    hsv_out_gray= cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    #cv2.imshow("houghin",hsv_out_gray)

    # Some notes on the HoughCircles function:
    #  Utilizes edge detection to draw tangent lines, recognizing a circle where perpendicular lines to tangents
    #  meet, depending on the intensity of the intersecting tangent lines.
    #  param1: higher threshold for Canny edge detection (lower is half of this)
    #  param2: accumulator threshold for circle center detection- i.e. the lower it is, the less circular an object
    #          needs to be to be recognized as a circle
    #  minDist: Specifies minimum distance between circles (the 4th input to the function)
    #  
    # from documentation: cv2.HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) â†’ circles
    circles = cv2.HoughCircles(hsv_out_gray,cv2.HOUGH_GRADIENT,1,minDist=5,param1=param1val,param2=param2val,minRadius=1,maxRadius=15)

    cv2.waitKey(1) # cv2.waitKey() is required to display images- waits 1 millisecond here

    img = copy.deepcopy(frame) # Sometimes if you copy stuff in Python, changes made to a copied variable end up in original
                                # which necessitates a deepcopy

    #DELETE THIS BLOCK ############
    #test_circle = cv2.ellipse(img,(600,220),(100,100),180,90,-90,255,5)
    #test_line = cv2.line(img, (230,300), (600,220), 255, 5)
    #nx, ny = (500,1) #500 colomns by 1 rows vector]
    #x = np.linspace(230,600,nx) #x vector
    #y = np.linspace(300,220,nx) #y vector, start and end reverse
    #xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
    #ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
    #print(xpoint)
    #print(ypoint)
    ###########################

    if isinstance(circles, type(None)) == 0:
        for circle in circles[0,:]:
            IDcircle(hsv, circle) # ID all the circles recognized by color
            # draw the outer circle
            cv2.circle(img,(circle[0],circle[1]),circle[2],(0,255,0),2)
            # draw the center of the circle
            cv2.circle(img,(circle[0],circle[1]),2,(0,0,255),3)

        if isinstance(ball, type(None)) == 0:
            # Draw a blue circle on the ball
            cv2.circle(img,(ball.pos[0],ball.pos[1]),10,(200,0,0),5)  
            cv2.putText(img, str(ball.pos), (ball.pos[0]+20,ball.pos[1]+20), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

        if (isinstance(roboIDmarks, type(None)) == 0) & (isinstance(roboList, type(None)) == 0):
            for robot in roboList:
                assignIDmarks(robot) # Assign the ID marks observed to their appropriate robot
                angle(robot)         # Determine angle of robots seen
                RoboID(robot)        # Give robots seen an ID

                # Draw the robot circles seen robot by robot
                # Draw a black circle on the centre of the robot
                cv2.circle(img,(robot.pos[0],robot.pos[1]),10,(0,0,0),3)
                

                #if isinstance(robot.angle, type(None)) == 0:
                #    # Display the robot's angle
                #    cv2.putText(img, str(round(robot.angle,1)), (robot.pos[0]+ 100, robot.pos[1] + 130), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's position
                #    cv2.putText(img, str(robot.pos), (robot.pos[0]+ 100, robot.pos[1] + 100), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's ID
                #    cv2.putText(img, robot.ID, (robot.pos[0]+ 100, robot.pos[1] + 70), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's Team
                #    cv2.putText(img, robot.team, (robot.pos[0]+ 100, robot.pos[1] + 40), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                for mark in robot.circles:
                    # Draw a black circle on every ID mark
                    cv2.circle(img,(mark[0],mark[1]),10,(0,0,0),3)  
        flag = 0 # go ahead and print "no circles detected" again

    elif(flag == 0):
        #print("no circles detected")
        flag = 1 # don't print this again

    # Display drawn on frame and original frame
    #cv2.imshow('circles on stream',img)
    cv2.imshow('original stream',frame)

    #if cv2.waitKey(1) & 0xFF == ord('\r'): # if enter is pressed, stop running
    #    break

    # when the ball does not get detected
    if (isinstance(ball, type(None)) != 0):
        ball = ballClass(temp1,temp2)  
    
    #This if statement is simply for initialization, there has to be a better way of doing this
    if(counter == 0):
        for rob in roboList:
            #Mike's added value stuff Initialization
            points = []
            tangents = []
            resolution = 0.2
            points.append([rob.pos[0],rob.pos[1]]) #Robot Position
            points.append([ball.pos[0],ball.pos[1]]) #Ball Position
            points.append([600,220]) #Net Position

            #Finding the angle at which the robot approaches
            approach_x = (points[2][0] - points[1][0])
            approach_y = (points[2][1] - points[1][1])

            common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
            approach_x = approach_x/common_divisor #Divide by common divisor
            approach_y = approach_y/common_divisor #Divide by common divisor

            #Tangents for alligning robot with ball and net
            tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
            tangents.append([approach_x, approach_y]) #Ball position
            tangents.append([approach_x, approach_y]) #Net position
        
    packet = bytearray()                    # ** Should this be within the for loop below?

   
    for rob in roboList:
        if(rob.ID != 0) & (isinstance(roboList, type(None)) == 0 ) & ((rob.ID == 10)):
            #robotsID = int(''.join(filter(str.isdigit,rob.ID))) # extracting integer ID number from rob.ID
            robotsID=rob.ID
            # if the robot has a radius larger than the distance between it and the edge of the frame
            # skip over this robot
            if(rob.radius < (rob.pos[1] - len(img[1])) or rob.radius < (rob.pos[0] - len(img[0]))):
                stoprobot(robotsID)
                continue
            else:
                #if(abs(abs(rob.angle)-180)>20 and counter>5):
                #    if (abs(rob.angle-test) >=200 and counter > 5):
                #        rob.angle=test#something is wrong with the angle measurement
                    
                #else:
                #    if (abs(abs( rob.angle)-abs(test)) >=50 and counter>5 ):
                #        rob.angle=test#something is wrong with the angle measurement
                test=rob.angle
                #print("rob.angle",rob.angle)
                # Display the robot's angle
                cv2.putText(img, str(round(rob.angle,1)), (rob.pos[0]+ 100, rob.pos[1] + 130), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's position
                cv2.putText(img, str(rob.pos), (rob.pos[0]+ 100, rob.pos[1] + 100), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's ID
                cv2.putText(img, 'ID'+str(rob.ID), (rob.pos[0]+ 100, rob.pos[1] + 70), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's Team
                cv2.putText(img, rob.team, (rob.pos[0]+ 100, rob.pos[1] + 40), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

                #Mike's Added Value 
                points.append([rob.pos[0],rob.pos[1]]) #Robot Position
                points.append([ball.pos[0],ball.pos[1]]) #Ball Position
                points.append([600,220]) #Net Position

                #Finding the angle at which the robot approaches FOR THE SPLINE
                approach_x = (points[2][0] - points[1][0])
                approach_y = (points[2][1] - points[1][1])
                #common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
                #approach_x = approach_x/common_divisor #Divide by common divisor
                #approach_y = approach_y/common_divisor #Divide by common divisor

                #Tangents for alligning robot with bafll and net
                tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
                tangents.append([approach_x, approach_y]) #Ball position
                tangents.append([approach_x, approach_y]) #Net position

                points = np.asarray(points)
                tangents = np.asarray(tangents)

                # Interpolate with different tangent lengths, but equal direction.
                scale = 0.01 #Tunable Parameter, the closer to 0 the tighter the spline, 0.01 is a good in between
                tangents_new = np.dot(tangents, scale*np.eye(2))
                #samples_new = np.float32(sampleCubicSplinesWithDerivative(points, tangents_new, resolution))

                endlocation=goalieMode(ball.pos)

                print(endlocation,'endlocation')
                if goalie_flag==1:
                    samples_new=splinePaths(rob.ID,ball.pos,resolution,'shoot')
                else:
                    samples_new=splinePaths(rob.ID,endlocation,resolution,'shoot')
                goalie_flag=0
                shootflag=1

                #print('r', resolution, 'r')
                #print('s', samples_new, 's')

                #Find the slope to the next point for the robot
                next_point_x =  np.float32(samples_new[round(len(samples_new)/10)][0] - points[0][0]) #Change in x between the robot and next point
                next_point_y =  np.float32(samples_new[round(len(samples_new)/10)][1] - points[0][1]) #Change in y between the robot and next point

                tangents[0][0] = math.atan2(next_point_y, next_point_x) - rob.angle #This value is the angle in radians that the robot must face for its path
                #print("tangents[0][0]", math.degrees(tangents[0][0]))
                tangents[0][1] = 1
                #print("tangents[0][1]", math.degrees(tangents[0][1]))
                tangents[1][0] = approach_x #x slope for the spline
                #print("tangents[1][0]", math.degrees(tangents[1][0]))
                tangents[1][1] = approach_y #y slope for the spline
                #print("tangents[1][1]", math.degrees(tangents[1][1]))
                tangents[2][0] = approach_x #x slope for the spline
                #print("tangents[2][0]", math.degrees(tangents[2][0]))
                tangents[2][1] = approach_y #y slope for the spline
                #print("tangents[2][1]", math.degrees(tangents[2][1]))
                #approach_x = (next_point_x)
                #approach_y = (next_point_y)
                points = np.asarray(points)
                tangents = np.asarray(tangents)
                trajectory = math.degrees(tangents[0][0]) #Angle in degrees


                #Display splines on the live feed & plot
                #path_plot = plt.scatter(samples3[:,0], samples3[:,1], marker='o', label='samples3')
                if(attacker_defender_flag == 0):
                    k = 0
                    for k in range(0,len(samples_new)):
                        cv2.circle(img, (samples_new[k,0], samples_new[k,1]), 1, (0, 255, 255),5)

                ####### Angle Control 
                if rob.angle == 999:
                    rob.angle=test

                #Mike's Added Value Deciding which error to use Based on Robot Position and Angle
                pos_error = ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5 #The absolute error between robot and ball
                angle_error = math.degrees(math.atan2(ball.pos[1]-rob.pos[1],ball.pos[0]-rob.pos[0])) - rob.angle #Angle error between robot and ball
                if (abs(angle_error)<180):
                        angle_error=angle_error
                elif (np.sign(angle_error)==-1):
                        angle_error=angle_error+360
                elif (np.sign(angle_error)==1):
                        angle_error=angle_error-360
                else:
                        print("done")

                if(attacker_defender_flag == 0):
                    error2 = math.degrees((math.atan2(samples_new[round(len(samples_new)/10)][1]-rob.pos[1], samples_new[round(len(samples_new)/10)][0]-rob.pos[0])))-rob.angle #error2 for Mike's Added Value
                    error1 = ((next_point_x)**2+(next_point_y)**2)**0.5 #error1 for Mike's Added value

                #Mike's Added Value Part 2 START
                #color = 255
                #cv2.line(img, (ball.pos[0],ball.pos[1]), (points[3][0],points[3][1]), color, 5)
                if(attacker_defender_flag == 1):
                    nx, ny = (500,1) #500 colomns by 1 rows vector]
                    x = np.linspace(ball.pos[0],600,nx) #x vector
                    y = np.linspace(ball.pos[1],220,nx) #y vector, start and end reversed

                    xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
                    ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
                    error1 = ((xpoint-rob.pos[0])**2+(ypoint-rob.pos[1])**2)**0.5 #error1 for Mike's Added value part 2
                    error2 = math.degrees((math.atan2(ypoint-rob.pos[1],xpoint-rob.pos[0])))-rob.angle
                   # print(xpoint)
                   # print(ypoint)
                #Mike's Added Value Part 2 END 

                if error1<5:
                    #error2=angle_new-rob.angle
                    kp1=10
                else:
                    kp2=5

                #if error1<5:
                 #   goalie_flag=1


                #regulate the angle to reduce ambiguity
                if (abs(error2)<180):
                        error2=error2
                elif (np.sign(error2)==-1):
                        error2=error2+360
                elif (np.sign(error2)==1):
                        error2=error2-360
                else:
                        print("done")
                print("error2",error2)

                intergral=intergral+error2
                ki=0.05
                derivative2=(error2-error_prior2) #Shouldn't this be divided by a dt?
                error_prior2=error2
                kp2=1.5
                ki=0.01
                kd2=0.5
                u2=  (kp2*error2)   +   (ki*intergral) 
                if (intergral > 8000):
                    intergral=8000
               
                derivative1=(error1-error_prior1)
                error_prior1=error1
                kd1=0.5
                kp1=10
                print("error1:",error1)
                #u1=  ( kp1*error1 )   +  ( kd1*derivative1 )
                u1=  ( kp1*error1 ) 
                
             
                ## Setting limits to the inputs 
                if(u1 > umax):
                    u1=umax
                if(u1 < -umax):
                    u1 = -umax
                #u2=0
                if(u2 > u2max):
                    u2=u2max
                if(u2 < -u2max):
                    u2 = -u2max


                if (abs(error2)>45):
                    u1=0

                # Assigning Individual Wheel velocities
                vr=u1+u2
                vl=u1-u2
                
                # Assigning the direction of motors based on the wheel velocities sign
                if vl > 0:
                    dirL=0
                else:
                    dirL=1

                if vr < 0:
                    dirR=0
                else:
                    dirR=1

                # Remove the sign in motor velocities
                Vr = abs(int(vr))
                Vl = abs(int(vl))

                # Assign the motor velocities to 0-256 range to send through 8bit UART
                #VrHex = int((Vr - VrMin)*255/ (VrMax - VrMin))
                #VlHex = int((Vl - VlMin)*255/ (VlMax - VlMin))
                VrHex = int(Vr*255/ VrMax)
                VlHex = int(Vl*255/ VlMax)

                if(VrHex == 0):
                    VrHex = 1
                if(VlHex == 0):
                    VlHex = 1

                #if (kickcounter>20): 
                if (abs(error1) < 3.5 and abs(error2) < 45 and kickcounter>10): 
                    kick= 0xFF
                    kickcounter=0
                else:
                    kick = 0

                print(kickcounter,'kickcounter')

                kickcounter=kickcounter+1

                #Mike's Added Value Kicking 
                if ((error1 < 20) and (error1 == ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5)):
                    VrHex = 0x01
                    VlHex = 0x01

                if VrHex>255:
                    VrHex=255;
                if VlHex>255:
                    VlHex=255;


                print("VlHex:",VlHex)
                print("VrHex:",VrHex)
                print("dirL:",dirL)
                print("dirR:",dirR)

                #VlHex=0
               # VrHex=0

                print(kick,'kick')

                counter = counter + 1
                packet.append(0xFF)
                packet.append(0x01)  #Robot ID
                packet.append(VrHex) #VrHex
                packet.append(dirR)  #dirR
                packet.append(VlHex) #VlHex
                packet.append(dirL)  #dirL
                #packet.append(kick)  #kick
                packet.append(0x00)  #kick
                packet.append(0xFF)
                KL25.write(packet)

                #data = KL25.read(4)
                #print(data.decode('ISO-8859-1'))
                points = [] #Reset points
                tangents = []#Reset tangents

    resize = cv2.resize(img, (2000,1500))
    cv2.imshow('circles on stream',resize)

#Path Palnning
def mainLoop1():
    print("new loop path planning\n\r")
    # Declaring global variables so they can be cleared every loop
    global roboList, roboIDmarks, circles, ball, IDdRobots, ball_possesor_id

    global error1,error_prior1,error2,error_prior2,dt,derivative1,L,R,dirR,dirL,umax,u2max,kp1
    global kp2,flag,kd1,kd2,VrMax,VlMax,temp1,temp2,test,counter,ki

    #Mikes Global Variables
    global points
    global tangents
    global samples_prev
    global next_point_x, next_point_y
    global intergral
    global kickcounter
   
    #cap = cv2.VideoCapture(cv2.CAP_DSHOW + 0) # 0 if your pc doesn't have a webcam, probably 1 if it does
    # https://stackoverflow.com/questions/52043671/opencv-capturing-imagem-with-black-side-bars
    # MSMF doesn't like being scaled up apparently, so switch from it (default) to DirectShow
    # so we can scale up the resolution read from the camera

    # Scaling up from 640x480 to HD 1280x720
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    

    #while(True):
    #  while(KL25.inWaiting()==0):

    ret,frame = cap.read() # reading the video capture into a dummy var and frame

    #cv2.waitKey(50)
        
    # Reinitializing robot data (prevents buildup of data accross frames)
    roboList = []
    roboIDmarks= []
    circles = []
    ball = None

    #Mike's Added Value Parameters
    points = []
    tangents = []
    resolution = 0.2 #was 0.2

    # Histogram equalization for colors (haven't tested with this)
    #img_yuv = cv2.cvtColor(ii, cv2.COLOR_BGR2YUV)

    ### equalize the histogram of the Y channel
    #img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])

    ### convert the YUV image back to RGB format
    #frame_yuv = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

    # blurring image for less errant circles and better color recognition later
    # d = 5 as that is the recommended nearest neighbour for real time
    # sigmaColor = 150 to produce large blending effect
    # sigmaSpace is limited by d, so I suspect it doesn't matter
    blurred_img = cv2.bilateralFilter(frame,8,150,150) 

    # HSV color space conversion
    hsv= cv2.cvtColor(blurred_img,cv2.COLOR_BGR2HSV)

    # Color masking, not necessary due to blurring, but might be worth looking into further
    #lower_rangeG = np.array([0,0,0]) # Hue, Saturation, Value mask lower limit
    #upper_rangeG = np.array([180,255,255]) # " , " , " " upper limit

    #mask = cv2.inRange(hsv, lower_rangeG, upper_rangeG) # mask for original frame with only good color
    #result = cv2.bitwise_and(blurred_img,blurred_img,mask=mask)
    result = blurred_img

    #cv2.imshow("blurred image",result)
  
    hsv_out_gray= cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    #cv2.imshow("houghin",hsv_out_gray)

    # Some notes on the HoughCircles function:
    #  Utilizes edge detection to draw tangent lines, recognizing a circle where perpendicular lines to tangents
    #  meet, depending on the intensity of the intersecting tangent lines.
    #  param1: higher threshold for Canny edge detection (lower is half of this)
    #  param2: accumulator threshold for circle center detection- i.e. the lower it is, the less circular an object
    #          needs to be to be recognized as a circle
    #  minDist: Specifies minimum distance between circles (the 4th input to the function)
    #  
    # from documentation: cv2.HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) â†’ circles
    circles = cv2.HoughCircles(hsv_out_gray,cv2.HOUGH_GRADIENT,1,minDist=5,param1=param1val,param2=param2val,minRadius=1,maxRadius=15)

    cv2.waitKey(1) # cv2.waitKey() is required to display images- waits 1 millisecond here

    img = copy.deepcopy(frame) # Sometimes if you copy stuff in Python, changes made to a copied variable end up in original
                                # which necessitates a deepcopy

    #DELETE THIS BLOCK ############
    #test_circle = cv2.ellipse(img,(600,220),(100,100),180,90,-90,255,5)
    #test_line = cv2.line(img, (230,300), (600,220), 255, 5)
    #nx, ny = (500,1) #500 colomns by 1 rows vector]
    #x = np.linspace(230,600,nx) #x vector
    #y = np.linspace(300,220,nx) #y vector, start and end reverse
    #xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
    #ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
    #print(xpoint)
    #print(ypoint)
    ###########################

    if isinstance(circles, type(None)) == 0:
        for circle in circles[0,:]:
            IDcircle(hsv, circle) # ID all the circles recognized by color
            # draw the outer circle
            cv2.circle(img,(circle[0],circle[1]),circle[2],(0,255,0),2)
            # draw the center of the circle
            cv2.circle(img,(circle[0],circle[1]),2,(0,0,255),3)

        if isinstance(ball, type(None)) == 0:
            # Draw a blue circle on the ball
            cv2.circle(img,(ball.pos[0],ball.pos[1]),10,(200,0,0),5)  
            cv2.putText(img, str(ball.pos), (ball.pos[0]+20,ball.pos[1]+20), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

        if (isinstance(roboIDmarks, type(None)) == 0) & (isinstance(roboList, type(None)) == 0):
            for robot in roboList:
                assignIDmarks(robot) # Assign the ID marks observed to their appropriate robot
                angle(robot)         # Determine angle of robots seen
                RoboID(robot)        # Give robots seen an ID

                # Draw the robot circles seen robot by robot
                # Draw a black circle on the centre of the robot
                cv2.circle(img,(robot.pos[0],robot.pos[1]),10,(0,0,0),3)
                

                #if isinstance(robot.angle, type(None)) == 0:
                #    # Display the robot's angle
                #    cv2.putText(img, str(round(robot.angle,1)), (robot.pos[0]+ 100, robot.pos[1] + 130), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's position
                #    cv2.putText(img, str(robot.pos), (robot.pos[0]+ 100, robot.pos[1] + 100), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's ID
                #    cv2.putText(img, robot.ID, (robot.pos[0]+ 100, robot.pos[1] + 70), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's Team
                #    cv2.putText(img, robot.team, (robot.pos[0]+ 100, robot.pos[1] + 40), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                for mark in robot.circles:
                    # Draw a black circle on every ID mark
                    cv2.circle(img,(mark[0],mark[1]),10,(0,0,0),3)  
        flag = 0 # go ahead and print "no circles detected" again

    elif(flag == 0):
        #print("no circles detected")
        flag = 1 # don't print this again

    # Display drawn on frame and original frame
    #cv2.imshow('circles on stream',img)
    cv2.imshow('original stream',frame)

    #if cv2.waitKey(1) & 0xFF == ord('\r'): # if enter is pressed, stop running
    #    break

    # when the ball does not get detected
    if (isinstance(ball, type(None)) != 0):
        ball = ballClass(temp1,temp2)  
    
    #This if statement is simply for initialization, there has to be a better way of doing this
    if(counter == 0):
        for rob in roboList:
            #Mike's added value stuff Initialization
            points = []
            tangents = []
            resolution = 0.2
            points.append([rob.pos[0],rob.pos[1]]) #Robot Position
            points.append([ball.pos[0],ball.pos[1]]) #Ball Position
            points.append([600,220]) #Net Position

            #Finding the angle at which the robot approaches
            approach_x = (points[2][0] - points[1][0])
            approach_y = (points[2][1] - points[1][1])

            common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
            approach_x = approach_x/common_divisor #Divide by common divisor
            approach_y = approach_y/common_divisor #Divide by common divisor

            #Tangents for alligning robot with ball and net
            tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
            tangents.append([approach_x, approach_y]) #Ball position
            tangents.append([approach_x, approach_y]) #Net position
        
    packet = bytearray()                    # ** Should this be within the for loop below?

   
    for rob in roboList:
        if(rob.ID != 0) & (isinstance(roboList, type(None)) == 0 ) & ((rob.ID == 10)):
            #robotsID = int(''.join(filter(str.isdigit,rob.ID))) # extracting integer ID number from rob.ID
            robotsID=rob.ID
            # if the robot has a radius larger than the distance between it and the edge of the frame
            # skip over this robot
            if(rob.radius < (rob.pos[1] - len(img[1])) or rob.radius < (rob.pos[0] - len(img[0]))):
                stoprobot(robotsID)
                continue
            else:
                #if(abs(abs(rob.angle)-180)>20 and counter>5):
                #    if (abs(rob.angle-test) >=200 and counter > 5):
                #        rob.angle=test#something is wrong with the angle measurement
                    
                #else:
                #    if (abs(abs( rob.angle)-abs(test)) >=50 and counter>5 ):
                #        rob.angle=test#something is wrong with the angle measurement
                test=rob.angle
                #print("rob.angle",rob.angle)
                # Display the robot's angle
                cv2.putText(img, str(round(rob.angle,1)), (rob.pos[0]+ 100, rob.pos[1] + 130), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's position
                cv2.putText(img, str(rob.pos), (rob.pos[0]+ 100, rob.pos[1] + 100), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's ID
                cv2.putText(img, 'ID'+str(rob.ID), (rob.pos[0]+ 100, rob.pos[1] + 70), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's Team
                cv2.putText(img, rob.team, (rob.pos[0]+ 100, rob.pos[1] + 40), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

                #Mike's Added Value 
                points.append([rob.pos[0],rob.pos[1]]) #Robot Position
                points.append([ball.pos[0],ball.pos[1]]) #Ball Position
                points.append([600,220]) #Net Position

                #Finding the angle at which the robot approaches FOR THE SPLINE
                approach_x = (points[2][0] - points[1][0])
                approach_y = (points[2][1] - points[1][1])
                #common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
                #approach_x = approach_x/common_divisor #Divide by common divisor
                #approach_y = approach_y/common_divisor #Divide by common divisor

                #Tangents for alligning robot with bafll and net
                tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
                tangents.append([approach_x, approach_y]) #Ball position
                tangents.append([approach_x, approach_y]) #Net position

                points = np.asarray(points)
                tangents = np.asarray(tangents)

                # Interpolate with different tangent lengths, but equal direction.
                scale = 0.01 #Tunable Parameter, the closer to 0 the tighter the spline, 0.01 is a good in between
                tangents_new = np.dot(tangents, scale*np.eye(2))
                #samples_new = np.float32(sampleCubicSplinesWithDerivative(points, tangents_new, resolution))

                if (ball == None):
                    endlocation=np.array([600,220])
                else:
                    endlocation=ball.pos

                samples_new=splinePaths(rob.ID,endlocation,resolution,'none')
                
                #print('r', resolution, 'r')
                #print('s', samples_new, 's')

                #Find the slope to the next point for the robot
                next_point_x =  np.float32(samples_new[round(len(samples_new)/10)][0] - points[0][0]) #Change in x between the robot and next point
                next_point_y =  np.float32(samples_new[round(len(samples_new)/10)][1] - points[0][1]) #Change in y between the robot and next point

                tangents[0][0] = math.atan2(next_point_y, next_point_x) - rob.angle #This value is the angle in radians that the robot must face for its path
                #print("tangents[0][0]", math.degrees(tangents[0][0]))
                tangents[0][1] = 1
                #print("tangents[0][1]", math.degrees(tangents[0][1]))
                tangents[1][0] = approach_x #x slope for the spline
                #print("tangents[1][0]", math.degrees(tangents[1][0]))
                tangents[1][1] = approach_y #y slope for the spline
                #print("tangents[1][1]", math.degrees(tangents[1][1]))
                tangents[2][0] = approach_x #x slope for the spline
                #print("tangents[2][0]", math.degrees(tangents[2][0]))
                tangents[2][1] = approach_y #y slope for the spline
                #print("tangents[2][1]", math.degrees(tangents[2][1]))
                #approach_x = (next_point_x)
                #approach_y = (next_point_y)
                points = np.asarray(points)
                tangents = np.asarray(tangents)
                trajectory = math.degrees(tangents[0][0]) #Angle in degrees


                #Display splines on the live feed & plot
                #path_plot = plt.scatter(samples3[:,0], samples3[:,1], marker='o', label='samples3')
                if(attacker_defender_flag == 0):
                    k = 0
                    for k in range(0,len(samples_new)):
                        cv2.circle(img, (samples_new[k,0], samples_new[k,1]), 1, (0, 255, 255),5)

                ####### Angle Control 
                if rob.angle == 999:
                    rob.angle=test

                #Mike's Added Value Deciding which error to use Based on Robot Position and Angle
                pos_error = ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5 #The absolute error between robot and ball
                angle_error = math.degrees(math.atan2(ball.pos[1]-rob.pos[1],ball.pos[0]-rob.pos[0])) - rob.angle #Angle error between robot and ball
                if (abs(angle_error)<180):
                        angle_error=angle_error
                elif (np.sign(angle_error)==-1):
                        angle_error=angle_error+360
                elif (np.sign(angle_error)==1):
                        angle_error=angle_error-360
                else:
                        print("done")

                if(attacker_defender_flag == 0):
                    if(abs(pos_error) <= 30 and abs(angle_error) <=5): #if the robot is close to the ball and is lined up
                        error2 = math.degrees((math.atan2(ball.pos[1]-rob.pos[1],ball.pos[0]-rob.pos[0])))-rob.angle
                        error1 = ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5
                    else:
                        error2 = math.degrees((math.atan2(samples_new[round(len(samples_new)/10)][1]-rob.pos[1], samples_new[round(len(samples_new)/10)][0]-rob.pos[0])))-rob.angle #error2 for Mike's Added Value
                        error1 = ((next_point_x)**2+(next_point_y)**2)**0.5 #error1 for Mike's Added value

                #Mike's Added Value Part 2 START
                #color = 255
                #cv2.line(img, (ball.pos[0],ball.pos[1]), (points[3][0],points[3][1]), color, 5)
                if(attacker_defender_flag == 1):
                    nx, ny = (500,1) #500 colomns by 1 rows vector]
                    x = np.linspace(ball.pos[0],600,nx) #x vector
                    y = np.linspace(ball.pos[1],220,nx) #y vector, start and end reversed

                    xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
                    ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
                    error1 = ((xpoint-rob.pos[0])**2+(ypoint-rob.pos[1])**2)**0.5 #error1 for Mike's Added value part 2
                    error2 = math.degrees((math.atan2(ypoint-rob.pos[1],xpoint-rob.pos[0])))-rob.angle
                   # print(xpoint)
                   # print(ypoint)
                #Mike's Added Value Part 2 END 

                if error1<5:
                    #error2=angle_new-rob.angle
                    kp1=10
                else:
                    kp2=5

                #regulate the angle to reduce ambiguity
                if (abs(error2)<180):
                        error2=error2
                elif (np.sign(error2)==-1):
                        error2=error2+360
                elif (np.sign(error2)==1):
                        error2=error2-360
                else:
                        print("done")
                print("error2",error2)

                intergral=intergral+error2
                ki=0.05
                derivative2=(error2-error_prior2) #Shouldn't this be divided by a dt?
                error_prior2=error2
                kp2=1.5
                ki=0.01
                kd2=0.5
                u2=  (kp2*error2)   +   (ki*intergral) 
                if (intergral > 8000):
                    intergral=8000
               
                derivative1=(error1-error_prior1)
                error_prior1=error1
                kd1=0.5
                kp1=10
                print("error1:",error1)
                #u1=  ( kp1*error1 )   +  ( kd1*derivative1 )
                u1=  ( kp1*error1 ) 
                
             
                ## Setting limits to the inputs 
                if(u1 > umax):
                    u1=umax
                if(u1 < -umax):
                    u1 = -umax
                #u2=0
                if(u2 > u2max):
                    u2=u2max
                if(u2 < -u2max):
                    u2 = -u2max


                if (abs(error2)>45):
                    u1=0
                
                # Assigning Individual Wheel velocities
                vr=u1+u2
                vl=u1-u2
                
                # Assigning the direction of motors based on the wheel velocities sign
                if vl > 0:
                    dirL=0
                else:
                    dirL=1

                if vr < 0:
                    dirR=0
                else:
                    dirR=1

                # Remove the sign in motor velocities
                Vr = abs(int(vr))
                Vl = abs(int(vl))

                # Assign the motor velocities to 0-256 range to send through 8bit UART
                #VrHex = int((Vr - VrMin)*255/ (VrMax - VrMin))
                #VlHex = int((Vl - VlMin)*255/ (VlMax - VlMin))
                VrHex = int(Vr*255/ VrMax)
                VlHex = int(Vl*255/ VlMax)

                if(VrHex == 0):
                    VrHex = 1
                if(VlHex == 0):
                    VlHex = 1

                #if (kickcounter>20): 
                if (abs(error1) < 3.5 and abs(error2) < 45 and kickcounter>10): 
                    kick= 0xFF
                    kickcounter=0
                else:
                    kick = 0

                print(kickcounter,'kickcounter')

                kickcounter=kickcounter+1

                #Mike's Added Value Kicking 
                if ((error1 < 20) and (error1 == ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5)):
                    VrHex = 0x01
                    VlHex = 0x01

                if VrHex>255:
                    VrHex=255;
                if VlHex>255:
                    VlHex=255;


                print("VlHex:",VlHex)
                print("VrHex:",VrHex)
                print("dirL:",dirL)
                print("dirR:",dirR)

                #VlHex=0
               # VrHex=0

                print(kick,'kick')

                counter = counter + 1
                packet.append(0xFF)
                packet.append(0x01)  #Robot ID
                packet.append(VrHex) #VrHex
                packet.append(dirR)  #dirR
                packet.append(VlHex) #VlHex
                packet.append(dirL)  #dirL
                packet.append(kick)  #kick
                #packet.append(0x00)  #kick
                packet.append(0xFF)
                KL25.write(packet)

                #data = KL25.read(4)
                #print(data.decode('ISO-8859-1'))
                points = [] #Reset points
                tangents = []#Reset tangents

    resize = cv2.resize(img, (2000,1500))
    cv2.imshow('circles on stream',resize)




def mainLoop2():
    print("new loop path planning\n\r")
    # Declaring global variables so they can be cleared every loop
    global roboList, roboIDmarks, circles, ball, IDdRobots, ball_possesor_id

    global error1,error_prior1,error2,error_prior2,dt,derivative1,L,R,dirR,dirL,umax,u2max,kp1
    global kp2,flag,kd1,kd2,VrMax,VlMax,temp1,temp2,test,counter,ki

    #Mikes Global Variables
    global points
    global tangents
    global samples_prev
    global next_point_x, next_point_y
    global intergral
    global kickcounter
   
    #cap = cv2.VideoCapture(cv2.CAP_DSHOW + 0) # 0 if your pc doesn't have a webcam, probably 1 if it does
    # https://stackoverflow.com/questions/52043671/opencv-capturing-imagem-with-black-side-bars
    # MSMF doesn't like being scaled up apparently, so switch from it (default) to DirectShow
    # so we can scale up the resolution read from the camera

    # Scaling up from 640x480 to HD 1280x720
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    

    #while(True):
    #  while(KL25.inWaiting()==0):

    ret,frame = cap.read() # reading the video capture into a dummy var and frame

    #cv2.waitKey(50)
        
    # Reinitializing robot data (prevents buildup of data accross frames)
    roboList = []
    roboIDmarks= []
    circles = []
    ball = None

    #Mike's Added Value Parameters
    points = []
    tangents = []
    resolution = 0.2 #was 0.2

    # Histogram equalization for colors (haven't tested with this)
    #img_yuv = cv2.cvtColor(ii, cv2.COLOR_BGR2YUV)

    ### equalize the histogram of the Y channel
    #img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])

    ### convert the YUV image back to RGB format
    #frame_yuv = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

    # blurring image for less errant circles and better color recognition later
    # d = 5 as that is the recommended nearest neighbour for real time
    # sigmaColor = 150 to produce large blending effect
    # sigmaSpace is limited by d, so I suspect it doesn't matter
    blurred_img = cv2.bilateralFilter(frame,8,150,150) 

    # HSV color space conversion
    hsv= cv2.cvtColor(blurred_img,cv2.COLOR_BGR2HSV)

    # Color masking, not necessary due to blurring, but might be worth looking into further
    #lower_rangeG = np.array([0,0,0]) # Hue, Saturation, Value mask lower limit
    #upper_rangeG = np.array([180,255,255]) # " , " , " " upper limit

    #mask = cv2.inRange(hsv, lower_rangeG, upper_rangeG) # mask for original frame with only good color
    #result = cv2.bitwise_and(blurred_img,blurred_img,mask=mask)
    result = blurred_img

    #cv2.imshow("blurred image",result)
  
    hsv_out_gray= cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    #cv2.imshow("houghin",hsv_out_gray)

    # Some notes on the HoughCircles function:
    #  Utilizes edge detection to draw tangent lines, recognizing a circle where perpendicular lines to tangents
    #  meet, depending on the intensity of the intersecting tangent lines.
    #  param1: higher threshold for Canny edge detection (lower is half of this)
    #  param2: accumulator threshold for circle center detection- i.e. the lower it is, the less circular an object
    #          needs to be to be recognized as a circle
    #  minDist: Specifies minimum distance between circles (the 4th input to the function)
    #  
    # from documentation: cv2.HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) â†’ circles
    circles = cv2.HoughCircles(hsv_out_gray,cv2.HOUGH_GRADIENT,1,minDist=5,param1=param1val,param2=param2val,minRadius=1,maxRadius=15)

    cv2.waitKey(1) # cv2.waitKey() is required to display images- waits 1 millisecond here

    img = copy.deepcopy(frame) # Sometimes if you copy stuff in Python, changes made to a copied variable end up in original
                                # which necessitates a deepcopy

    #DELETE THIS BLOCK ############
    #test_circle = cv2.ellipse(img,(600,220),(100,100),180,90,-90,255,5)
    #test_line = cv2.line(img, (230,300), (600,220), 255, 5)
    #nx, ny = (500,1) #500 colomns by 1 rows vector]
    #x = np.linspace(230,600,nx) #x vector
    #y = np.linspace(300,220,nx) #y vector, start and end reverse
    #xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
    #ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
    #print(xpoint)
    #print(ypoint)
    ###########################

    if isinstance(circles, type(None)) == 0:
        for circle in circles[0,:]:
            IDcircle(hsv, circle) # ID all the circles recognized by color
            # draw the outer circle
            cv2.circle(img,(circle[0],circle[1]),circle[2],(0,255,0),2)
            # draw the center of the circle
            cv2.circle(img,(circle[0],circle[1]),2,(0,0,255),3)

        if isinstance(ball, type(None)) == 0:
            # Draw a blue circle on the ball
            cv2.circle(img,(ball.pos[0],ball.pos[1]),10,(200,0,0),5)  
            cv2.putText(img, str(ball.pos), (ball.pos[0]+20,ball.pos[1]+20), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

        if (isinstance(roboIDmarks, type(None)) == 0) & (isinstance(roboList, type(None)) == 0):
            for robot in roboList:
                assignIDmarks(robot) # Assign the ID marks observed to their appropriate robot
                angle(robot)         # Determine angle of robots seen
                RoboID(robot)        # Give robots seen an ID

                # Draw the robot circles seen robot by robot
                # Draw a black circle on the centre of the robot
                cv2.circle(img,(robot.pos[0],robot.pos[1]),10,(0,0,0),3)
                

                #if isinstance(robot.angle, type(None)) == 0:
                #    # Display the robot's angle
                #    cv2.putText(img, str(round(robot.angle,1)), (robot.pos[0]+ 100, robot.pos[1] + 130), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's position
                #    cv2.putText(img, str(robot.pos), (robot.pos[0]+ 100, robot.pos[1] + 100), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's ID
                #    cv2.putText(img, robot.ID, (robot.pos[0]+ 100, robot.pos[1] + 70), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's Team
                #    cv2.putText(img, robot.team, (robot.pos[0]+ 100, robot.pos[1] + 40), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                for mark in robot.circles:
                    # Draw a black circle on every ID mark
                    cv2.circle(img,(mark[0],mark[1]),10,(0,0,0),3)  
        flag = 0 # go ahead and print "no circles detected" again

    elif(flag == 0):
        #print("no circles detected")
        flag = 1 # don't print this again

    # Display drawn on frame and original frame
    #cv2.imshow('circles on stream',img)
    cv2.imshow('original stream',frame)

    #if cv2.waitKey(1) & 0xFF == ord('\r'): # if enter is pressed, stop running
    #    break

    # when the ball does not get detected
    if (isinstance(ball, type(None)) != 0):
        ball = ballClass(temp1,temp2)  
    
    #This if statement is simply for initialization, there has to be a better way of doing this
    if(counter == 0):
        for rob in roboList:
            #Mike's added value stuff Initialization
            points = []
            tangents = []
            resolution = 0.2
            points.append([rob.pos[0],rob.pos[1]]) #Robot Position
            points.append([ball.pos[0],ball.pos[1]]) #Ball Position
            points.append([600,220]) #Net Position

            #Finding the angle at which the robot approaches
            approach_x = (points[2][0] - points[1][0])
            approach_y = (points[2][1] - points[1][1])

            common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
            approach_x = approach_x/common_divisor #Divide by common divisor
            approach_y = approach_y/common_divisor #Divide by common divisor

            #Tangents for alligning robot with ball and net
            tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
            tangents.append([approach_x, approach_y]) #Ball position
            tangents.append([approach_x, approach_y]) #Net position
        
    packet = bytearray()                    # ** Should this be within the for loop below?

   
    for rob in roboList:
        if(rob.ID != 0) & (isinstance(roboList, type(None)) == 0 ) & ((rob.ID == 10)):
            #robotsID = int(''.join(filter(str.isdigit,rob.ID))) # extracting integer ID number from rob.ID
            robotsID=rob.ID
            # if the robot has a radius larger than the distance between it and the edge of the frame
            # skip over this robot
            if(rob.radius < (rob.pos[1] - len(img[1])) or rob.radius < (rob.pos[0] - len(img[0]))):
                stoprobot(robotsID)
                continue
            else:
                #if(abs(abs(rob.angle)-180)>20 and counter>5):
                #    if (abs(rob.angle-test) >=200 and counter > 5):
                #        rob.angle=test#something is wrong with the angle measurement
                    
                #else:
                #    if (abs(abs( rob.angle)-abs(test)) >=50 and counter>5 ):
                #        rob.angle=test#something is wrong with the angle measurement
                test=rob.angle
                #print("rob.angle",rob.angle)
                # Display the robot's angle
                cv2.putText(img, str(round(rob.angle,1)), (rob.pos[0]+ 100, rob.pos[1] + 130), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's position
                cv2.putText(img, str(rob.pos), (rob.pos[0]+ 100, rob.pos[1] + 100), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's ID
                cv2.putText(img, 'ID'+str(rob.ID), (rob.pos[0]+ 100, rob.pos[1] + 70), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's Team
                cv2.putText(img, rob.team, (rob.pos[0]+ 100, rob.pos[1] + 40), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

                #Mike's Added Value 
                points.append([rob.pos[0],rob.pos[1]]) #Robot Position
                points.append([ball.pos[0],ball.pos[1]]) #Ball Position
                points.append([600,220]) #Net Position

                #Finding the angle at which the robot approaches FOR THE SPLINE
                approach_x = (points[2][0] - points[1][0])
                approach_y = (points[2][1] - points[1][1])
                #common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
                #approach_x = approach_x/common_divisor #Divide by common divisor
                #approach_y = approach_y/common_divisor #Divide by common divisor

                #Tangents for alligning robot with bafll and net
                tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
                tangents.append([approach_x, approach_y]) #Ball position
                tangents.append([approach_x, approach_y]) #Net position

                points = np.asarray(points)
                tangents = np.asarray(tangents)

                # Interpolate with different tangent lengths, but equal direction.
                scale = 0.01 #Tunable Parameter, the closer to 0 the tighter the spline, 0.01 is a good in between
                tangents_new = np.dot(tangents, scale*np.eye(2))
                #samples_new = np.float32(sampleCubicSplinesWithDerivative(points, tangents_new, resolution))

                netloc=np.array([640,220])
                if (ball == None):
                    endlocation=netloc
                else:
                    endlocation=ball.pos

                endlocation,action=aicontrol(rob.ID,netloc,np.array([640,480]))

                print(endlocation,'endlocation')
                print(action)

                shootflag=0
                if (action=='shoot'):
                    endlocation=netloc
                    shootflag=1

                samples_new=splinePaths(rob.ID,endlocation,resolution,action)
                
                #print('r', resolution, 'r')
                #print('s', samples_new, 's')

                #Find the slope to the next point for the robot
                next_point_x =  np.float32(samples_new[round(len(samples_new)/10)][0] - points[0][0]) #Change in x between the robot and next point
                next_point_y =  np.float32(samples_new[round(len(samples_new)/10)][1] - points[0][1]) #Change in y between the robot and next point

                tangents[0][0] = math.atan2(next_point_y, next_point_x) - rob.angle #This value is the angle in radians that the robot must face for its path
                #print("tangents[0][0]", math.degrees(tangents[0][0]))
                tangents[0][1] = 1
                #print("tangents[0][1]", math.degrees(tangents[0][1]))
                tangents[1][0] = approach_x #x slope for the spline
                #print("tangents[1][0]", math.degrees(tangents[1][0]))
                tangents[1][1] = approach_y #y slope for the spline
                #print("tangents[1][1]", math.degrees(tangents[1][1]))
                tangents[2][0] = approach_x #x slope for the spline
                #print("tangents[2][0]", math.degrees(tangents[2][0]))
                tangents[2][1] = approach_y #y slope for the spline
                #print("tangents[2][1]", math.degrees(tangents[2][1]))
                #approach_x = (next_point_x)
                #approach_y = (next_point_y)
                points = np.asarray(points)
                tangents = np.asarray(tangents)
                trajectory = math.degrees(tangents[0][0]) #Angle in degrees


                #Display splines on the live feed & plot
                #path_plot = plt.scatter(samples3[:,0], samples3[:,1], marker='o', label='samples3')
                if(attacker_defender_flag == 0):
                    k = 0
                    for k in range(0,len(samples_new)):
                        cv2.circle(img, (samples_new[k,0], samples_new[k,1]), 1, (0, 255, 255),5)

                ####### Angle Control 
                if rob.angle == 999:
                    rob.angle=test

                #Mike's Added Value Deciding which error to use Based on Robot Position and Angle
                pos_error = ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5 #The absolute error between robot and ball
                angle_error = math.degrees(math.atan2(ball.pos[1]-rob.pos[1],ball.pos[0]-rob.pos[0])) - rob.angle #Angle error between robot and ball
                if (abs(angle_error)<180):
                        angle_error=angle_error
                elif (np.sign(angle_error)==-1):
                        angle_error=angle_error+360
                elif (np.sign(angle_error)==1):
                        angle_error=angle_error-360
                else:
                        print("done")

                if(attacker_defender_flag == 0):
                    if(abs(pos_error) <= 30 and abs(angle_error) <=5): #if the robot is close to the ball and is lined up
                        error2 = math.degrees((math.atan2(ball.pos[1]-rob.pos[1],ball.pos[0]-rob.pos[0])))-rob.angle
                        error1 = ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5
                    else:
                        error2 = math.degrees((math.atan2(samples_new[round(len(samples_new)/10)][1]-rob.pos[1], samples_new[round(len(samples_new)/10)][0]-rob.pos[0])))-rob.angle #error2 for Mike's Added Value
                        error1 = ((next_point_x)**2+(next_point_y)**2)**0.5 #error1 for Mike's Added value

                #Mike's Added Value Part 2 START
                #color = 255
                #cv2.line(img, (ball.pos[0],ball.pos[1]), (points[3][0],points[3][1]), color, 5)
                if(attacker_defender_flag == 1):
                    nx, ny = (500,1) #500 colomns by 1 rows vector]
                    x = np.linspace(ball.pos[0],600,nx) #x vector
                    y = np.linspace(ball.pos[1],220,nx) #y vector, start and end reversed

                    xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
                    ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
                    error1 = ((xpoint-rob.pos[0])**2+(ypoint-rob.pos[1])**2)**0.5 #error1 for Mike's Added value part 2
                    error2 = math.degrees((math.atan2(ypoint-rob.pos[1],xpoint-rob.pos[0])))-rob.angle
                   # print(xpoint)
                   # print(ypoint)
                #Mike's Added Value Part 2 END 

                if error1<5:
                    #error2=angle_new-rob.angle
                    kp1=20*2
                else:
                    kp1=10*2

                #regulate the angle to reduce ambiguity
                if (abs(error2)<180):
                        error2=error2
                elif (np.sign(error2)==-1):
                        error2=error2+360
                elif (np.sign(error2)==1):
                        error2=error2-360
                else:
                        print("done")
                print("error2",error2)

                intergral=intergral+error2
                ki=0.05
                derivative2=(error2-error_prior2) #Shouldn't this be divided by a dt?
                error_prior2=error2
                kp2=1.5
                ki=0.01
                kd2=0.5
                u2=  (kp2*error2)   +   (ki*intergral) 
                if (intergral > 8000):
                    intergral=8000
               
                derivative1=(error1-error_prior1)
                error_prior1=error1
                kd1=0.5
                kp1=10
                print("error1:",error1)
                #u1=  ( kp1*error1 )   +  ( kd1*derivative1 )
                u1=  ( kp1*error1 ) 
                
             
                ## Setting limits to the inputs 
                if(u1 > umax):
                    u1=umax
                if(u1 < -umax):
                    u1 = -umax
                #u2=0
                if(u2 > u2max):
                    u2=u2max
                if(u2 < -u2max):
                    u2 = -u2max


                if (abs(error2)>45):
                    u1=0
                
                if (shootflag==1):
                    u1=0

                # Assigning Individual Wheel velocities
                vr=u1+u2
                vl=u1-u2
                
                # Assigning the direction of motors based on the wheel velocities sign
                if vl > 0:
                    dirL=0
                else:
                    dirL=1

                if vr < 0:
                    dirR=0
                else:
                    dirR=1

                print(dirR,'dirR')
                print(dirL,'dirL')

                # Remove the sign in motor velocities
                Vr = abs(int(vr))
                Vl = abs(int(vl))

                # Assign the motor velocities to 0-256 range to send through 8bit UART
                #VrHex = int((Vr - VrMin)*255/ (VrMax - VrMin))
                #VlHex = int((Vl - VlMin)*255/ (VlMax - VlMin))
                VrHex = int(Vr*255/ VrMax)
                VlHex = int(Vl*255/ VlMax)

                if(VrHex == 0):
                    VrHex = 1
                if(VlHex == 0):
                    VlHex = 1

                if (abs(error1) < 3.5 and abs(error2) <10 and shootflag==1 and kickcounter>20): 
                    kick= 0xFF
                    kickcounter=0
                else:
                    kick = 0

                kickcounter=kickcounter+1
                #Mike's Added Value Kicking 
                if ((error1 < 20) and (error1 == ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5)):
                    VrHex = 0x01
                    VlHex = 0x01

                if VrHex>255:
                    VrHex=255;
                if VlHex>255:
                    VlHex=255;


                print("VlHex:",VlHex)
                print("VrHex:",VrHex)
                print("dirL:",dirL)
                print("dirR:",dirR)

                counter = counter + 1
                packet.append(0xFF)
                packet.append(0x01)  #Robot ID
                packet.append(VrHex) #VrHex
                packet.append(dirR)  #dirR
                packet.append(VlHex) #VlHex
                packet.append(dirL)  #dirL
                #packet.append(kick)  #kick
                packet.append(0x00)  #kick
                packet.append(0xFF)
                KL25.write(packet)

                #data = KL25.read(4)
                #print(data.decode('ISO-8859-1'))
                points = [] #Reset points
                tangents = []#Reset tangents

    resize = cv2.resize(img, (2000,1500))
    cv2.imshow('circles on stream',resize)

    
# Nick's AI
def mainLoop3():
    print("new loop path planning\n\r")
    # Declaring global variables so they can be cleared every loop
    global roboList, roboIDmarks, circles, ball, IDdRobots, ball_possesor_id

    global error1,error_prior1,error2,error_prior2,dt,derivative1,L,R,dirR,dirL,umax,u2max,kp1
    global kp2,flag,kd1,kd2,VrMax,VlMax,temp1,temp2,test,counter,ki

    #Mikes Global Variables
    global points
    global tangents
    global samples_prev
    global next_point_x, next_point_y
    global intergral
   
    #cap = cv2.VideoCapture(cv2.CAP_DSHOW + 0) # 0 if your pc doesn't have a webcam, probably 1 if it does
    # https://stackoverflow.com/questions/52043671/opencv-capturing-imagem-with-black-side-bars
    # MSMF doesn't like being scaled up apparently, so switch from it (default) to DirectShow
    # so we can scale up the resolution read from the camera

    # Scaling up from 640x480 to HD 1280x720
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)
    

    #while(True):
    #  while(KL25.inWaiting()==0):

    ret,frame = cap.read() # reading the video capture into a dummy var and frame

    #cv2.waitKey(50)
        
    # Reinitializing robot data (prevents buildup of data accross frames)
    roboList = []
    roboIDmarks= []
    circles = []
    ball = None

    #Mike's Added Value Parameters
    points = []
    tangents = []
    resolution = 0.2 #was 0.2

    # Histogram equalization for colors (haven't tested with this)
    #img_yuv = cv2.cvtColor(ii, cv2.COLOR_BGR2YUV)

    ### equalize the histogram of the Y channel
    #img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])

    ### convert the YUV image back to RGB format
    #frame_yuv = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

    # blurring image for less errant circles and better color recognition later
    # d = 5 as that is the recommended nearest neighbour for real time
    # sigmaColor = 150 to produce large blending effect
    # sigmaSpace is limited by d, so I suspect it doesn't matter
    blurred_img = cv2.bilateralFilter(frame,8,150,150) 

    # HSV color space conversion
    hsv= cv2.cvtColor(blurred_img,cv2.COLOR_BGR2HSV)

    # Color masking, not necessary due to blurring, but might be worth looking into further
    #lower_rangeG = np.array([0,0,0]) # Hue, Saturation, Value mask lower limit
    #upper_rangeG = np.array([180,255,255]) # " , " , " " upper limit

    #mask = cv2.inRange(hsv, lower_rangeG, upper_rangeG) # mask for original frame with only good color
    #result = cv2.bitwise_and(blurred_img,blurred_img,mask=mask)
    result = blurred_img

    #cv2.imshow("blurred image",result)
  
    hsv_out_gray= cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    #cv2.imshow("houghin",hsv_out_gray)

    # Some notes on the HoughCircles function:
    #  Utilizes edge detection to draw tangent lines, recognizing a circle where perpendicular lines to tangents
    #  meet, depending on the intensity of the intersecting tangent lines.
    #  param1: higher threshold for Canny edge detection (lower is half of this)
    #  param2: accumulator threshold for circle center detection- i.e. the lower it is, the less circular an object
    #          needs to be to be recognized as a circle
    #  minDist: Specifies minimum distance between circles (the 4th input to the function)
    #  
    # from documentation: cv2.HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) â†’ circles
    circles = cv2.HoughCircles(hsv_out_gray,cv2.HOUGH_GRADIENT,1,minDist=5,param1=param1val,param2=param2val,minRadius=1,maxRadius=15)

    cv2.waitKey(1) # cv2.waitKey() is required to display images- waits 1 millisecond here

    img = copy.deepcopy(frame) # Sometimes if you copy stuff in Python, changes made to a copied variable end up in original
                                # which necessitates a deepcopy

    #DELETE THIS BLOCK ############
    #test_circle = cv2.ellipse(img,(600,220),(100,100),180,90,-90,255,5)
    #test_line = cv2.line(img, (230,300), (600,220), 255, 5)
    #nx, ny = (500,1) #500 colomns by 1 rows vector]
    #x = np.linspace(230,600,nx) #x vector
    #y = np.linspace(300,220,nx) #y vector, start and end reverse
    #xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
    #ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
    #print(xpoint)
    #print(ypoint)
    ###########################

    if isinstance(circles, type(None)) == 0:
        for circle in circles[0,:]:
            IDcircle(hsv, circle) # ID all the circles recognized by color
            # draw the outer circle
            cv2.circle(img,(circle[0],circle[1]),circle[2],(0,255,0),2)
            # draw the center of the circle
            cv2.circle(img,(circle[0],circle[1]),2,(0,0,255),3)

        if isinstance(ball, type(None)) == 0:
            # Draw a blue circle on the ball
            cv2.circle(img,(ball.pos[0],ball.pos[1]),10,(200,0,0),5)  
            cv2.putText(img, str(ball.pos), (ball.pos[0]+20,ball.pos[1]+20), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

        if (isinstance(roboIDmarks, type(None)) == 0) & (isinstance(roboList, type(None)) == 0):
            for robot in roboList:
                assignIDmarks(robot) # Assign the ID marks observed to their appropriate robot
                angle(robot)         # Determine angle of robots seen
                RoboID(robot)        # Give robots seen an ID

                # Draw the robot circles seen robot by robot
                # Draw a black circle on the centre of the robot
                cv2.circle(img,(robot.pos[0],robot.pos[1]),10,(0,0,0),3)
                

                #if isinstance(robot.angle, type(None)) == 0:
                #    # Display the robot's angle
                #    cv2.putText(img, str(round(robot.angle,1)), (robot.pos[0]+ 100, robot.pos[1] + 130), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's position
                #    cv2.putText(img, str(robot.pos), (robot.pos[0]+ 100, robot.pos[1] + 100), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's ID
                #    cv2.putText(img, robot.ID, (robot.pos[0]+ 100, robot.pos[1] + 70), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                #    # Display the robot's Team
                #    cv2.putText(img, robot.team, (robot.pos[0]+ 100, robot.pos[1] + 40), 
                #                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                for mark in robot.circles:
                    # Draw a black circle on every ID mark
                    cv2.circle(img,(mark[0],mark[1]),10,(0,0,0),3)  
        flag = 0 # go ahead and print "no circles detected" again

    elif(flag == 0):
        #print("no circles detected")
        flag = 1 # don't print this again

    # Display drawn on frame and original frame
    #cv2.imshow('circles on stream',img)
    cv2.imshow('original stream',frame)

    #if cv2.waitKey(1) & 0xFF == ord('\r'): # if enter is pressed, stop running
    #    break

    # when the ball does not get detected
    if (isinstance(ball, type(None)) != 0):
        ball = ballClass(temp1,temp2)  
    
    #This if statement is simply for initialization, there has to be a better way of doing this
    if(counter == 0):
        for rob in roboList:
            #Mike's added value stuff Initialization
            points = []
            tangents = []
            resolution = 0.2
            points.append([rob.pos[0],rob.pos[1]]) #Robot Position
            points.append([ball.pos[0],ball.pos[1]]) #Ball Position
            points.append([600,220]) #Net Position

            #Finding the angle at which the robot approaches
            approach_x = (points[2][0] - points[1][0])
            approach_y = (points[2][1] - points[1][1])

            common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
            approach_x = approach_x/common_divisor #Divide by common divisor
            approach_y = approach_y/common_divisor #Divide by common divisor

            #Tangents for alligning robot with ball and net
            tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
            tangents.append([approach_x, approach_y]) #Ball position
            tangents.append([approach_x, approach_y]) #Net position
        
    packet = bytearray()                    # ** Should this be within the for loop below?

    # ***********************************************************************************************
    # ADDING NICKS FUNCTIONS:
    id=[]
    flag=1;
    for rob in roboList:
        if (rob.ID != 0) & (isinstance(roboList, type(None)) == 0):
            id.append([rob.ID, rob.pos[0], rob.pos[1], rob.angle])
            flag=0;

    # id.append([9, 300, 50, 20])

    id=np.array(id)
    
    print("ID TESTING (Before Algorithms)\n")
    count_rob(id)
    count_al_op(id)
    print(str(id))

    roboListGUI=[]
    roboListGUI=roboList

    ballGUI=ball
    if flag==0:
        #print('ENTER CHECK')

        grid_to_pxl_ratio()
        

        coords_arr_grd = pxl_2_grid(id)
        print(str(coords_arr_grd) + "\n")

        global op_loc_point_vals
        op_loc_point_vals = bounds_to_arr(field_bounds)

        # Testing Greater Loop 1
        print("ID TESTING (After Algorithms)\n")
        point_vals = 0
        coords_arr_grd = greater_loop_1(coords_arr_grd)
        # coords_arr_grd = greater_loop_2(coords_arr_grd)
        # print(str(op_loc_point_vals))
        print(str(coords_arr_grd))
        coords_arr_new = grd_2_pxl(coords_arr_grd)
        print(str(coords_arr_new) + "\n")
        print(str(ser_check_vals) + "\n")


    for rob in roboList:
        if(rob.ID != 0) & (isinstance(roboList, type(None)) == 0 ) & (rob.ID == 10):
            #robotsID = int(''.join(filter(str.isdigit,rob.ID))) # extracting integer ID number from rob.ID
            robotsID=rob.ID
            # if the robot has a radius larger than the distance between it and the edge of the frame
            # skip over this robot
            if(rob.radius < (rob.pos[1] - len(img[1])) or rob.radius < (rob.pos[0] - len(img[0]))):
                stoprobot(robotsID)
                continue
            else:
                #if(abs(abs(rob.angle)-180)>20 and counter>5):
                #    if (abs(rob.angle-test) >=200 and counter > 5):
                #        rob.angle=test#something is wrong with the angle measurement
                    
                #else:
                #    if (abs(abs( rob.angle)-abs(test)) >=50 and counter>5 ):
                #        rob.angle=test#something is wrong with the angle measurement
                test=rob.angle
                #print("rob.angle",rob.angle)
                # Display the robot's angle
                cv2.putText(img, str(round(rob.angle,1)), (rob.pos[0]+ 100, rob.pos[1] + 130), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's position
                cv2.putText(img, str(rob.pos), (rob.pos[0]+ 100, rob.pos[1] + 100), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's ID
                cv2.putText(img, 'ID'+str(rob.ID), (rob.pos[0]+ 100, rob.pos[1] + 70), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)
                # Display the robot's Team
                cv2.putText(img, rob.team, (rob.pos[0]+ 100, rob.pos[1] + 40), 
                            cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 3)

                #Mike's Added Value 
                points.append([rob.pos[0],rob.pos[1]]) #Robot Position
                points.append([ball.pos[0],ball.pos[1]]) #Ball Position
                points.append([600,220]) #Net Position

                #Finding the angle at which the robot approaches FOR THE SPLINE
                approach_x = (points[2][0] - points[1][0])
                approach_y = (points[2][1] - points[1][1])
                #common_divisor = abs(gcd(approach_x,approach_y)) #Absolute value of the greatest common divisor
                #approach_x = approach_x/common_divisor #Divide by common divisor
                #approach_y = approach_y/common_divisor #Divide by common divisor

                #Tangents for alligning robot with bafll and net
                tangents.append([math.tan(45*np.pi/180),1]) #Robot position, Slope converted from radians, this value is whatever angle the robot is currently facing
                tangents.append([approach_x, approach_y]) #Ball position
                tangents.append([approach_x, approach_y]) #Net position

                points = np.asarray(points)
                tangents = np.asarray(tangents)

                # Interpolate with different tangent lengths, but equal direction.
                scale = 0.01 #Tunable Parameter, the closer to 0 the tighter the spline, 0.01 is a good in between
                tangents_new = np.dot(tangents, scale*np.eye(2))
                #samples_new = np.float32(sampleCubicSplinesWithDerivative(points, tangents_new, resolution))

                if (ball == None):
                    endlocation=np.array([600,220])
                else:
                    endlocation=ball.pos

                pos_flg = 0
                i = 0
                while i in range(rob_num) and not(pos_flg):
                    if coords_arr_grd[i][0] == ball_possesor_id:
                        pos_flg = 1
                    i = i+1

                if pos_flg == 1:
                    for i in range(rob_num):
                        if coords_arr_new[i][0] == 10:
                            endlocation=np.array([coords_arr_new[i][1], coords_arr_new[i][2]])
                            angle_new = coords_arr_new[i][3]

                print(str(endlocation))

                samples_new=splinePaths(rob.ID,endlocation,resolution,'none')
                
                #print('r', resolution, 'r')
                #print('s', samples_new, 's')

                #Find the slope to the next point for the robot
                next_point_x =  np.float32(samples_new[round(len(samples_new)/10)][0] - points[0][0]) #Change in x between the robot and next point
                next_point_y =  np.float32(samples_new[round(len(samples_new)/10)][1] - points[0][1]) #Change in y between the robot and next point

                tangents[0][0] = math.atan2(next_point_y, next_point_x) - rob.angle #This value is the angle in radians that the robot must face for its path
                #print("tangents[0][0]", math.degrees(tangents[0][0]))
                tangents[0][1] = 1
                #print("tangents[0][1]", math.degrees(tangents[0][1]))
                tangents[1][0] = approach_x #x slope for the spline
                #print("tangents[1][0]", math.degrees(tangents[1][0]))
                tangents[1][1] = approach_y #y slope for the spline
                #print("tangents[1][1]", math.degrees(tangents[1][1]))
                tangents[2][0] = approach_x #x slope for the spline
                #print("tangents[2][0]", math.degrees(tangents[2][0]))
                tangents[2][1] = approach_y #y slope for the spline
                #print("tangents[2][1]", math.degrees(tangents[2][1]))
                #approach_x = (next_point_x)
                #approach_y = (next_point_y)
                points = np.asarray(points)
                tangents = np.asarray(tangents)
                trajectory = math.degrees(tangents[0][0]) #Angle in degrees


                #Display splines on the live feed & plot
                #path_plot = plt.scatter(samples3[:,0], samples3[:,1], marker='o', label='samples3')
                if(attacker_defender_flag == 0):
                    k = 0
                    for k in range(0,len(samples_new)):
                        cv2.circle(img, (samples_new[k,0], samples_new[k,1]), 1, (0, 255, 255),5)

                ####### Angle Control 
                if rob.angle == 999:
                    rob.angle=test

                #Mike's Added Value Deciding which error to use Based on Robot Position and Angle
                pos_error = ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5 #The absolute error between robot and ball
                angle_error = math.degrees(math.atan2(ball.pos[1]-rob.pos[1],ball.pos[0]-rob.pos[0])) - rob.angle #Angle error between robot and ball
                if (abs(angle_error)<180):
                        angle_error=angle_error
                elif (np.sign(angle_error)==-1):
                        angle_error=angle_error+360
                elif (np.sign(angle_error)==1):
                        angle_error=angle_error-360
                else:
                        print("done")

                if(attacker_defender_flag == 0):
                    if(abs(pos_error) <= 30 and abs(angle_error) <=5): #if the robot is close to the ball and is lined up
                        error2 = math.degrees((math.atan2(ball.pos[1]-rob.pos[1],ball.pos[0]-rob.pos[0])))-rob.angle
                        error1 = ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5
                    else:
                        error2 = math.degrees((math.atan2(samples_new[round(len(samples_new)/10)][1]-rob.pos[1], samples_new[round(len(samples_new)/10)][0]-rob.pos[0])))-rob.angle #error2 for Mike's Added Value
                        error1 = ((next_point_x)**2+(next_point_y)**2)**0.5 #error1 for Mike's Added value

                #Mike's Added Value Part 2 START
                #color = 255
                #cv2.line(img, (ball.pos[0],ball.pos[1]), (points[3][0],points[3][1]), color, 5)
                if(attacker_defender_flag == 1):
                    nx, ny = (500,1) #500 colomns by 1 rows vector]
                    x = np.linspace(ball.pos[0],600,nx) #x vector
                    y = np.linspace(ball.pos[1],220,nx) #y vector, start and end reversed

                    xpoint = x[round(len(x)*8/10)] #Going to rounded 8/10ths the way through the x vector
                    ypoint = y[round(len(y)*8/10)] #Going to rounded 8/10ths the way through the y vector
                    error1 = ((xpoint-rob.pos[0])**2+(ypoint-rob.pos[1])**2)**0.5 #error1 for Mike's Added value part 2
                    error2 = math.degrees((math.atan2(ypoint-rob.pos[1],xpoint-rob.pos[0])))-rob.angle
                   # print(xpoint)
                   # print(ypoint)
                #Mike's Added Value Part 2 END 

                if error1<5:
                    error2=angle_new-rob.angle
                    kp1=20
                else:
                    kp2=10

                #regulate the angle to reduce ambiguity
                if (abs(error2)<180):
                        error2=error2
                elif (np.sign(error2)==-1):
                        error2=error2+360
                elif (np.sign(error2)==1):
                        error2=error2-360
                else:
                        print("done")
                print("error2",error2)

                intergral=intergral+error2
                ki=0.05
                derivative2=(error2-error_prior2) #Shouldn't this be divided by a dt?
                error_prior2=error2
                kp2=1.5
                ki=0.01
                kd2=0.5
                u2=  (kp2*error2)   +   (ki*intergral) 
                if (intergral > 8000):
                    intergral=8000
               
                derivative1=(error1-error_prior1)
                error_prior1=error1
                kd1=0.5
                kp1=10
                print("error1:",error1)
                #u1=  ( kp1*error1 )   +  ( kd1*derivative1 )
                u1=  ( kp1*error1 ) 
                
             
                ## Setting limits to the inputs 
                if(u1 > umax):
                    u1=umax
                if(u1 < -umax):
                    u1 = -umax
                #u2=0
                if(u2 > u2max):
                    u2=u2max
                if(u2 < -u2max):
                    u2 = -u2max


                if (abs(error2)>45):
                    u1=0
                #u1=0

                # Assigning Individual Wheel velocities
                vr=u1+u2
                vl=u1-u2
                
                # Assigning the direction of motors based on the wheel velocities sign
                if vl > 0:
                    dirL=0
                else:
                    dirL=1

                if vr < 0:
                    dirR=0
                else:
                    dirR=1

                print(dirR,'dirR')
                print(dirL,'dirL')

                # Remove the sign in motor velocities
                Vr = abs(int(vr))
                Vl = abs(int(vl))

                # Assign the motor velocities to 0-256 range to send through 8bit UART
                #VrHex = int((Vr - VrMin)*255/ (VrMax - VrMin))
                #VlHex = int((Vl - VlMin)*255/ (VlMax - VlMin))
                VrHex = int(Vr*255/ VrMax)
                VlHex = int(Vl*255/ VlMax)

                if(VrHex == 0):
                    VrHex = 1
                if(VlHex == 0):
                    VlHex = 1

                if (abs(error1) < 3.5 and abs(error2) <10): 
                    kick= 0xFF
                else:
                    kick = 0

                #Mike's Added Value Kicking 
                if ((error1 < 20) and (error1 == ((ball.pos[0]-rob.pos[0])**2+(ball.pos[1]-rob.pos[1])**2)**0.5)):
                    VrHex = 0x01
                    VlHex = 0x01

                if VrHex>255:
                    VrHex=255;
                if VlHex>255:
                    VlHex=255;


                print("VlHex:",VlHex)
                print("VrHex:",VrHex)
                print("dirL:",dirL)
                print("dirR:",dirR)

                counter = counter + 1
                packet.append(0xFF)
                packet.append(0x01)  #Robot ID
                packet.append(VrHex) #VrHex
                packet.append(dirR)  #dirR
                packet.append(VlHex) #VlHex
                packet.append(dirL)  #dirL
                #packet.append(kick)  #kick
                packet.append(0x00)  #kick
                packet.append(0xFF)
                KL25.write(packet)

                #data = KL25.read(4)
                #print(data.decode('ISO-8859-1'))
                points = [] #Reset points
                tangents = []#Reset tangents

    resize = cv2.resize(img, (1000,750))
    cv2.imshow('circles on stream',resize)

def plotData():
    if(radioflag == 0):
        del angleRecording[0]
        anglestddev = np.std(angleRecording)
        anglemean = np.mean(angleRecording)
        text = '\u03BC = '+str(round(anglemean,2))+'\n\u03C3 = '+str(round(anglestddev,2))

        xstddev = np.std(posRecording[0])
        ystddev = np.std(posRecording[1])
        xmean = np.mean(posRecording[0])
        ymean = np.mean(posRecording[1])
        text2 = r'$\mu_x$ = '+str(int(xmean))+r' $\mu_y$ = '+str(int(ymean))+'\n'+r'$\sigma_x$ = '+str(round(xstddev,2))+r' $\sigma_y$ = '+str(round(ystddev,2))

        del mainLoopTime[0]
        timemean = np.mean(mainLoopTime)
        timestddev = np.std(mainLoopTime)
        text3 = '\u03BC = '+str(round(timemean,2))+'\n\u03C3 = '+str(round(timestddev,2))

        plt.figure(1)
        y,x,_ = plt.hist(angleRecording, color = 'blue', edgecolor = 'black', bins = 100)
        x = int(x.max()-0.2*(x.max()-x.min()))
        y = int(y.max()*0.8)
        plt.title('Histogram of Angular Position Readings')
        plt.xlabel('Angle')
        plt.ylabel('Number of Readings')
        plt.text(x,y,text,bbox=dict(facecolor = 'white',alpha=0.5))

        plt.figure(2)
        x2 = int(max(posRecording[0])-(max(posRecording[0])-min(posRecording[0]))*0.25)
        y2 = int(max(posRecording[1])-(max(posRecording[1])-min(posRecording[1]))*0.2)
        plt.hist2d(posRecording[0],posRecording[1])
        plt.title('Heatmap of Positional Readings')
        plt.xlabel('x Position')
        plt.ylabel('y Position')
        plt.text(x2,y2,text2,color = 'w',bbox=dict(facecolor = 'white',alpha=0.5))

        plt.figure(3)
        y3,x3,_ = plt.hist(mainLoopTime, color = 'blue', edgecolor = 'black', bins = 50)
        x3 = x3.max()-0.2*(x3.max()-x3.min())
        y3 = y3.max()*0.8
        plt.title('Histogram of Overall Loop Time')
        plt.ylabel('Number of Readings')
        plt.xlabel('Time Elapsed in Seconds')
        plt.text(x3,y3,text3,bbox=dict(facecolor = 'white',alpha=0.5))

    if(radioflag == 1):
        plt.figure(1)
        plt.plot(Actual_X)
        plt.title('X Position')
        plt.ylabel('Position (Pixels)')
        plt.xlabel('Time Elapsed in Seconds')

        plt.figure(2)
        plt.plot(Actual_Y)
        plt.title('Y Position')
        plt.ylabel('Position (Pixels)')
        plt.xlabel('Time Elapsed in Seconds')

        plt.figure(3)
        plt.plot(Actual_Angle)
        plt.title('Angle (deg)')
        plt.ylabel('Angle')
        plt.xlabel('Time Elapsed in Seconds')

        plt.figure(4)
        plt.plot(Input_V)
        plt.title('Forward Velocity Input')
        plt.xlabel('Time Elapsed in Seconds')

        plt.figure(5)
        plt.plot(Input_W)
        plt.title('Angular Velocity Input')
        plt.xlabel('Time Elapsed in Seconds')

    plt.show()

def run():
    print('RUN')
    app = QApplication(sys.argv)
    window = roboGUI()
    window.show()
    print('test1')
    sys.exit(app.exec_())
 
breakpointthing = None
class Worker(QObject):
    finished = pyqtSignal()

    def __init__(self):
        super(Worker, self).__init__()
        self.working = True

    def work(self):
        while(self.working):
            sys.settrace = breakpointthing
            if(radioflag == 0):
                mainLoop()
            elif(radioflag == 1):
                mainLoop1()
            elif(radioflag == 2):
                mainLoop2()
            elif(radioflag == 3):
                mainLoop3()
            elif(radioflag == 4):
                mainLoop4()
        print("program has been stopped")
        while(True):
            stoprobot('all') # when stop button pressed, stop robots
        
        sys.exit()
            

class roboGUI(QMainWindow):
    def __init__(self, *args, **kwargs):
        super(roboGUI,self).__init__()
        self.window = QWidget(self)
        self.setCentralWidget(self.window)
        self.resize(400,100)
        self.setWindowTitle("roboGUI")
        self.layout = QVBoxLayout()

        self.buttons = QHBoxLayout()

        self.startButton = QPushButton("START",self)
        #self.startButton.setSizePolicy(QSizePolicy.Fixed,QSizePolicy.Expanding)
        #self.startButton.resize(self.startButton.minimumSizeHint())
        self.startButton.setMinimumSize(self.startButton.minimumSizeHint())
        self.startButton.setMinimumHeight(80)
        self.buttons.addWidget(self.startButton)
        self.stopButton = QPushButton("STOP",self)
        #self.stopButton.setSizePolicy(QSizePolicy.Preferred,QSizePolicy.Expanding)
        self.stopButton.setMinimumSize(self.stopButton.minimumSizeHint())
        self.stopButton.setMinimumHeight(80)
        self.buttons.addWidget(self.stopButton)

        self.layout.addLayout(self.buttons)

        self.sliders = QHBoxLayout()
        self.slidersleft = QVBoxLayout()
        self.slidersright = QGridLayout()

        self.param1text = QHBoxLayout()
        self.param1title = QLabel("Parameter 1")
        self.param1value = QLabel(str(param1val))
        self.param1slider = QSlider(Qt.Horizontal)
        self.param1slider.setMinimum(1)
        self.param1slider.setMaximum(250)
        self.param1slider.setValue(param1val)
        self.param1slider.setTickInterval(1)
        self.param1text.addWidget(self.param1title)
        self.param1text.addWidget(self.param1value)
        self.slidersleft.addLayout(self.param1text)
        self.slidersleft.addWidget(self.param1slider)
        
        self.param2text = QHBoxLayout()
        self.param2title = QLabel("Parameter 2")
        self.param2value = QLabel(str(param2val))
        self.param2slider = QSlider(Qt.Horizontal)
        self.param2slider.setMinimum(1)
        self.param2slider.setMaximum(50)
        self.param2slider.setValue(param2val)
        self.param2slider.setTickInterval(1)
        self.param2text.addWidget(self.param2title)
        self.param2text.addWidget(self.param2value)
        self.slidersleft.addLayout(self.param2text)
        self.slidersleft.addWidget(self.param2slider)

        self.valuetext = QHBoxLayout()
        self.valuetitle = QLabel("Minimum Value for Color")
        self.valuevalue = QLabel(str(valueMin))
        self.valueslider = QSlider(Qt.Horizontal)
        self.valueslider.setMinimum(0)
        self.valueslider.setMaximum(255)
        self.valueslider.setValue(valueMin)
        self.valueslider.setTickInterval(1)
        self.valueslider.setSizePolicy(QSizePolicy.Preferred,QSizePolicy.Fixed)
        self.valuetext.addWidget(self.valuetitle)
        self.valuetext.addWidget(self.valuevalue)
        self.slidersleft.addLayout(self.valuetext)
        self.slidersleft.addWidget(self.valueslider)

        self.kptext = QHBoxLayout()
        self.kptitle = QLabel("Kp Value:")
        self.kpvalue = QLabel(str(kp))
        self.kpvalue.setFixedWidth(30)
        self.kptext.addWidget(self.kptitle)
        self.kptext.addWidget(self.kpvalue)
        self.kpslider = QSlider(Qt.Vertical)
        self.kpslider.setMinimum(0)
        self.kpslider.setMaximum(500)
        self.kpslider.setValue(kp)
        self.kpslider.setTickInterval(5)
        self.kpslider.setSizePolicy(QSizePolicy.Fixed,QSizePolicy.Expanding)

        self.kdtext = QHBoxLayout()
        self.kdtitle = QLabel("Kd Value:")
        self.kdvalue = QLabel(str(kd))
        self.kdvalue.setFixedWidth(30)
        self.kdtext.addWidget(self.kdtitle)
        self.kdtext.addWidget(self.kdvalue)
        self.kdslider = QSlider(Qt.Vertical)
        self.kdslider.setMinimum(0)
        self.kdslider.setMaximum(500)
        self.kdslider.setValue(kd)
        self.kdslider.setTickInterval(5)
        self.kdslider.setSizePolicy(QSizePolicy.Fixed,QSizePolicy.Expanding)

        self.slidersright.addLayout(self.kptext,0,0)
        self.slidersright.addLayout(self.kdtext,0,1)
        self.slidersright.addWidget(self.kpslider,1,0)
        self.slidersright.addWidget(self.kdslider,1,1)

        self.sliders.addLayout(self.slidersleft)
        self.sliders.addLayout(self.slidersright)
        self.layout.addLayout(self.sliders)

        self.mainButtons = QVBoxLayout()
        self.pathPlanningButtons = QHBoxLayout()
        self.mainButton_group = QButtonGroup()

        self.normalMain = QRadioButton("Normal Main")
        self.normalMain.setChecked(True)
        self.normalMain.toggled.connect(self.mainSwitcher)
        self.mainButton_group.addButton(self.normalMain)
        self.mainButtons.addWidget(self.normalMain)

        self.feedbackLinMain = QRadioButton("Path Planning")
        self.feedbackLinMain.toggled.connect(self.mainSwitcher)
        self.mainButton_group.addButton(self.feedbackLinMain)
        self.mainButtons.addWidget(self.feedbackLinMain)

        self.kalmanFilterMain = QRadioButton("Markov Algorithm")
        self.kalmanFilterMain.toggled.connect(self.mainSwitcher)
        self.mainButton_group.addButton(self.kalmanFilterMain)
        self.mainButtons.addWidget(self.kalmanFilterMain)

        self.goaliemode = QRadioButton("Goalie Mode")
        self.goaliemode.toggled.connect(self.mainSwitcher)
        self.mainButton_group.addButton(self.goaliemode)
        self.mainButtons.addWidget(self.goaliemode)

        self.pathPlanningMain = QRadioButton("Greedy Algorithm")
        self.pathPlanningMain.toggled.connect(self.mainSwitcher)
        self.mainButton_group.addButton(self.pathPlanningMain)
        #attacker_defender_flag
        self.pathPlanning_group = QButtonGroup()
        self.attacker = QRadioButton("Offensive Mode")
        self.attacker.toggled.connect(self.pathSwitcher)
        self.defender = QRadioButton("Defensive Mode")
        self.defender.toggled.connect(self.pathSwitcher)
        self.pathPlanning_group.addButton(self.attacker)
        self.pathPlanning_group.addButton(self.defender)
        self.pathPlanningButtons.addWidget(self.pathPlanningMain)
        self.pathPlanningButtons.addWidget(self.attacker)
        self.pathPlanningButtons.addWidget(self.defender)
        self.mainButtons.addLayout(self.pathPlanningButtons)

        self.layout.addLayout(self.mainButtons)

        self.recordData = QCheckBox("Record data")
        self.recordData.stateChanged.connect(self.recordFlagSwitcher)
        self.layout.addWidget(self.recordData)

        self.window.setLayout(self.layout)
        self.window.setSizePolicy(QSizePolicy.Preferred,QSizePolicy.Expanding)
        
        self.thread = None
        self.worker = None

        self.param1slider.valueChanged[int].connect(self.changedValue_param1)
        self.param2slider.valueChanged[int].connect(self.changedValue_param2)
        self.valueslider.valueChanged[int].connect(self.changedValue_valueMin)
        self.kpslider.valueChanged[int].connect(self.changedValue_kp)
        self.kdslider.valueChanged[int].connect(self.changedValue_kd)
        self.startButton.clicked.connect(self.startLoop)

        #self.gui = MyWidget()
        #self.gui.show()

    def startLoop(self):
        breakpointthing = sys.gettrace()
        self.thread = QThread()
        self.worker = Worker()
        self.worker.moveToThread(self.thread)

        self.thread.started.connect(self.worker.work)
        self.stopButton.clicked.connect(self.stopLoop)
        self.worker.finished.connect(self.thread.quit)
        self.worker.finished.connect(self.worker.deleteLater)
        self.worker.finished.connect(self.thread.deleteLater)

        self.thread.start()

    def stopLoop(self):
        #plotData()
        self.worker.working = False

    def changedValue_param1(self, value):
        global param1val
        param1val = value
        self.param1value.setText(str(param1val))
    def changedValue_param2(self, value):
        global param2val
        param2val = value
        self.param2value.setText(str(param2val))
    def changedValue_valueMin(self, value):
        global valueMin
        valueMin = value
        self.valuevalue.setText(str(valueMin))
    def changedValue_kp(self, value):
        global kp
        kp = value/100
        self.kpvalue.setText(str(kp))
    def changedValue_kd(self, value):
        global kd
        kd = value/100
        self.kdvalue.setText(str(kd))

    def mainSwitcher(self):
        global radioflag
        if(self.normalMain.isChecked()):
            radioflag = 0
        elif(self.feedbackLinMain.isChecked()):
            radioflag = 1
        elif(self.kalmanFilterMain.isChecked()):
            radioflag = 2
        elif(self.pathPlanningMain.isChecked()):
            radioflag = 3
        elif(self.goaliemode.isChecked()):
            radioflag = 4


    def pathSwitcher(self):
        global attacker_defender_flag
        if(self.attacker.isChecked()):
            attacker_defender_flag = 0
            print("attacker mode")
        if(self.defender.isChecked()):
            attacker_defender_flag = 1
            print("defender mode")

    def recordFlagSwitcher(self):
        global recordFlag
        if(self.recordData.isChecked()):
            recordFlag = 1
            print("now recording data...")
        else:
            recordFlag = 0


    sys._excepthook = sys.excepthook 
    def exception_hook(exctype, value, traceback):
      #  print(exctype, value, traceback)
        sys._excepthook(exctype, value, traceback) 
        sys.exit(1) 
    sys.excepthook = exception_hook 

class MyWidget(QtWidgets.QWidget):

    def __init__(self, parent=None):#Setting GUI parameters
        QtWidgets.QWidget.__init__(self, parent)
        p = self.palette()
        feild=QColor.fromRgb(0,128,0,alpha = 255)
        p.setColor(self.backgroundRole(), feild)
        self.setPalette(p)
        self.pen = QtGui.QPen(QtGui.QColor(0,0,0))                      # set lineColor
        self.pen.setWidth(3)                                            # set lineWidth
        self.brush = QtGui.QBrush(QtGui.QColor(0,0,0,255))              # set fillColor 
        self.setFixedSize(640+250, 480)

        layout = QHBoxLayout()
        self.b1 = QCheckBox("Robot Position")
        self.b1.setChecked(True)
        self.b1.toggled.connect(lambda:self.btnstate(self.b1))
        self.b1.move(10,10)
        layout.addWidget(self.b1)

        self.b2 = QCheckBox("Robot Angle")
        self.b2.setChecked(True)
        self.b2.toggled.connect(lambda:self.btnstate(self.b2))
        layout.addWidget(self.b2)

        self.b3 = QCheckBox("Robot ID")
        self.b3.setChecked(True)
        self.b3.toggled.connect(lambda:self.btnstate(self.b3))
        layout.addWidget(self.b3)

        self.b4 = QCheckBox("Ball Position")
        self.b4.setChecked(True)
        self.b4.toggled.connect(lambda:self.btnstate(self.b4))
        layout.addWidget(self.b4)

        self.position=1
        self.angle=1
        self.ID=1
        self.ball=1

        self.setLayout(layout)

    def btnstate(self,b):#Checkbox functions
        if b.text() == "Robot Position":
            if b.isChecked() == True:
                print(b.text()+" is selected")
                self.position=1
            else:
                print(b.text()+" is deselected")
                self.position=0

        if b.text() == "Robot Angle":
            if b.isChecked() == True:
                print(b.text()+" is selected")
                self.angle=1
            else:
                print(b.text()+" is deselected")
                self.angle=0

        if b.text() == "Robot ID":
            if b.isChecked() == True:
                print(b.text()+" is selected")
                self.ID=1
            else:
                print(b.text()+" is deselected")
                self.ID=0

        if b.text() == "Ball Position":
            if b.isChecked() == True:
                print(b.text()+" is selected")
                self.ball=1
            else:
                print(b.text()+" is deselected")
                self.ball=0
    def paintEvent(self, event):#Drawn event to update GUI
        global roboListGUI
        global ballGUI

        self.b1.move(10,70)
        self.b2.move(10,170)
        self.b3.move(10,270)
        self.b4.move(10,370)

        offsetg=250

        robtemp=roboListGUI

        #Need to define the paths due to potention bug, make sure the number of robots on the field does not exeed the number of QPainterPath()'s
        pathrobot = [QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath()]
        pathcenter = [QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath()]
        path1 = [QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath()]
        path2 = [QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath()]
        path3 = [QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath()]
        path4 = [QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath(), QPainterPath()]
        pathball = QPainterPath()
        painter=QPainter(self)

        painter.setBrush(QColor(255,255,255))
        painter.drawRect(0, 0,offsetg,480)

        size=10;
        if ballGUI != None: #Drawing the ball
            pathball.addEllipse(ballGUI.pos[0]+offsetg,ballGUI.pos[1],size,size)
            painter.setBrush(QColor(255,140,0))
            painter.drawPath(pathball)

            painter.setPen(QColor(255, 255, 255))
            if self.ball:
                painter.drawText(ballGUI.pos[0]+10+offsetg, ballGUI.pos[1], str(ballGUI.pos))
            painter.setPen(QColor(0, 0, 0))

            ii=0;

        for rob in robtemp:#Drawing the robots
            if (rob.ID !=0):

                offset=20;
                angle=-rob.angle+90
                arad=angle*(3.14/180)

                #Determining the colors of the robots
                if rob.circles[0][2]=='P':
                    rc11=255
                    rc12=105
                    rc13=180
                else:
                    rc11=0
                    rc12=255
                    rc13=0

                if rob.circles[1][2]=='P':
                    rc21=255
                    rc22=105
                    rc23=180
                else:
                    rc21=0
                    rc22=255
                    rc23=0

                if rob.circles[2][2]=='P':
                    rc31=255
                    rc32=105
                    rc33=180
                else:
                    rc31=0
                    rc32=255
                    rc33=0

                if rob.circles[3][2]=='P':
                    rc41=255
                    rc42=105
                    rc43=180
                else:
                    rc41=0
                    rc42=255
                    rc43=0

                if rob.team=='B':
                    rc51=0
                    rc52=0
                    rc53=255
                else:
                    rc51=255
                    rc52=255
                    rc53=0

                xpos=rob.pos[0]+offsetg #Calculating the offsets and how to draw the robots
                ypos=rob.pos[1]
                pathrobot[ii].moveTo(xpos, ypos)
                h=100;
                w=100;
                pathrobot[ii].arcTo(xpos-w/2, ypos-h/2, w, h, angle, 180)

                painter.setBrush(QColor(0, 0, 0))
                painter.drawPath(pathrobot[ii])

                painter.setPen(QColor(255, 255, 255))
                yoffset=0
                if self.position:
                    painter.drawText(xpos+50, ypos, str(rob.pos))
                    yoffset=yoffset+30
                if self.angle:
                    painter.drawText(xpos+50, ypos+yoffset, str(round(rob.angle,1)))
                    yoffset=yoffset+30
                if self.ID:
                    painter.drawText(xpos+50, ypos+yoffset, 'ID: ' + str(rob.ID))
                painter.setPen(QColor(0, 0, 0))
                
                #Drawing the robots
                pathcenter[ii].addEllipse(xpos-size/2-(w/4)*math.sin(arad),ypos-size/2-(w/4)*math.cos(arad),size,size)
                painter.setBrush(QColor(rc51,rc52,rc53))
                painter.drawPath(pathcenter[ii])

                path1x=xpos-size/2-(w/3)*math.sin(arad+0.4)
                path1y=ypos-size/2-(w/3)*math.cos(arad+0.4)

                path2x=xpos-size/2-(w/3)*math.sin(arad-0.4)
                path2y=ypos-size/2-(w/3)*math.cos(arad-0.4)

                val=15;
                path3x=path1x+val*math.sin(arad)
                path3y=path1y+val*math.cos(arad)

                path4x=path2x+val*math.sin(arad)
                path4y=path2y+val*math.cos(arad)

                path3[ii].addEllipse(path3x,path3y,size,size)
                painter.setBrush(QColor(rc11, rc12, rc13))
                painter.drawPath(path3[ii])

                path4[ii].addEllipse(path4x,path4y,size,size)
                painter.setBrush(QColor(rc21, rc22, rc23))
                painter.drawPath(path4[ii])

                path1[ii].addEllipse(path1x,path1y,size,size)
                painter.setBrush(QColor(rc31, rc32, rc33))
                painter.drawPath(path1[ii])

                path2[ii].addEllipse(path2x,path2y,size,size)
                painter.setBrush(QColor(rc41, rc42, rc43))
                painter.drawPath(path2[ii])

                ii=ii+1;
                
    def updategui(self):
        self.update()
        #print('repaint')

app2 = QtWidgets.QApplication(sys.argv) 
widget = MyWidget()

# NICHOLAS' CODE FUNCTIONS******************************************
# IMPORTED LIBRARIES
import math

# FUNCTIONS:
def grid_to_pxl_ratio():

    global pxl_size, field_bounds

    x_rat = pxl_size[0]/field_bounds[1]
    y_rat = pxl_size[1]/field_bounds[3]

    return [x_rat, y_rat]

def count_rob(coords_arr):
    # Function to return the number of robots identified by the vision algorithm
    # Inputs: coords_arr - matrix of robot information for check
    # Outputs: rob_num - number of rows identified (symbolizing number of robots)
    global rob_num

    rob_num = len(coords_arr)

def pxl_2_grid(coords_arr):
    # Function used to convert the information gathered in pixels to point on our imaginary grid placed over the field of
    # play
    # Inputs: coords_arr - matrix containing all robot information [id, x, y, angle]
    # Outputs: coords_arr_grd - matrix containing all robot information on grid [id, x, y, angle]

    global pxl_grd_ratio, rob_num

    coords_arr_grd = []        # Initiate empty matrix
    for i in range(rob_num):
        dummy_arr = [0, 0, 0, 0]      # Initiate dummy arr for appending
        dummy_arr[0] = coords_arr[i][0]

        # Modulus code to determine weather to ceil() or floor() to round x coordinate to nearest grid position
        if (coords_arr[i][1] % pxl_grd_ratio[0] > math.floor(pxl_grd_ratio[0] / 2)):
            dummy_arr[1] = math.ceil(coords_arr[i][1]/pxl_grd_ratio[0])
        else:
            dummy_arr[1] = math.floor(coords_arr[i][1] / pxl_grd_ratio[0])

        # Modulus code to determine weather to ceil() or floor() to round y coordinate to nearest grid position
        if coords_arr[i][2] % pxl_grd_ratio[1] > math.floor(pxl_grd_ratio[1] / 2):
            dummy_arr[2] = math.ceil(coords_arr[i][2]/pxl_grd_ratio[1])
        else:
            dummy_arr[2] = math.floor(coords_arr[i][2] / pxl_grd_ratio[1])

        dummy_arr[3] = coords_arr[i][3]

        coords_arr_grd.append(dummy_arr)

    return coords_arr_grd

def grd_2_pxl(coords_arr_grd):

    global pxl_grd_ratio, rob_num

    new_pos = []        # Initiate empty return array
    for i in range(rob_num):
        if coords_arr_grd[i][0] >16:
            new_pos.append(coords_arr_grd[i])
        else:
            dummy_arr = [0, 0, 0, 0]
            
            dummy_arr[0] = coords_arr_grd[i][0]
            dummy_arr[1] = math.floor(coords_arr_grd[i][1] * pxl_grd_ratio[0])
            dummy_arr[2] = math.floor(coords_arr_grd[i][2] * pxl_grd_ratio[1])
            dummy_arr[3] = coords_arr_grd[i][3]

            new_pos.append(dummy_arr)

    return new_pos

def count_al_op(coords_arr_grd):

    global al_n, op_n, rob_num

    al_n = 0; op_n = 0

    for i in range(rob_num):
        if coords_arr_grd[i][0] <= 16:
            al_n = al_n+1
        else:
            op_n = op_n+1

def point_prox(xpoint, ypoint, oIDInfo):

    # Function used to determine the proximity of a given point on the field to a specified opponent
    # Inputs:   x coordinate of relevant point
    #           y coordinate of relevant point
    #           opponent ID information
    # Outputs:  proximity array detailing magnitude and angle of dirrection (respectiely)

    if oIDInfo[1] - xpoint == 0:
        ang = math.atan((oIDInfo[2] - ypoint) / (0.0000001))        # Special case in which the two are at 90 deg from one another
    else:
        ang = math.atan((oIDInfo[2] - ypoint) / (oIDInfo[1] - xpoint))  # General case

    ang = ang * 180 / 3.14159       # Convert angle from rad to degrees
    ang = ang + 180

    if ang >= 180:
        ang = ang - 180

    mag = math.sqrt(pow(oIDInfo[2] - ypoint, 2) + math.pow(oIDInfo[1] - xpoint, 2))     # Determine the magnitudinal distance between the points and the opponent

    # debugging
    # print(str(ang))
    # print(str(mag))

    ans = [mag, ang]        # Array for return
    return ans

def check_LOS_net(aIDInfo, oIDInfo):

    # Function used to determine if there is a clear line of sight between an ally and the net w.r.t. specified opponent
    # Inputs:   ally ID information
    #           opponent ID information
    # Output:   status of opponents interference in path between the specified ally and the net (1 = clear, 0 = unclear)

    global net_location     # Aquire necessary global variables

    dx = net_location[0] - aIDInfo[1]       # Determine the distance in the x direction
    dy = net_location[1] - aIDInfo[2]       # Determine the distance in the y direction

    j = 0       # Counting variable for point divisions
    point_div = []      # Initiate blank array
    for i in range(50):
        point_div.append(j)
        j = j + 1/50

    for i in range(50):
        prox = point_prox(aIDInfo[1] + point_div[i] * dx, aIDInfo[2] + point_div[i] * dy, oIDInfo)        #For each division along path to net, check proximity to the opponent
        if prox[0] <= 2:
            return 0        #If path is found to be within 1/2 a specified unit, break the function and return a "FALSE" flag
        # ***********

    return 1        #If no interference is found, will return a "TRUE" flag

def check_LOS_al(aIDInfo1, aIDInfo2, oIDInfo):

    # Function used to determine if there is a clear line of sight between two allys w.r.t. specified opponent
    # Inputs:   ally ID information ball holder
    #           ally ID information ball recipient
    #           opponent ID information
    # Output:   status of opponents interference in path between the specified allys (1 = clear, 0 = unclear)

    dX = aIDInfo2[1] - aIDInfo1[1]
    dY = aIDInfo2[2] - aIDInfo1[2]

    j = 0  # Counting variable for point divisions
    point_div = []  # Initiate blank array
    for i in range(50):
        point_div.append(j)
        j = j + 1 / 50

    for i in range(50):
        prox = point_prox(aIDInfo1[1] + point_div[i] * dX, aIDInfo1[2] + point_div[i] * dY, oIDInfo)
        if prox[0] <= 1.7:
            return 0

    return 1

def bounds_to_arr(field_bounds):

    # Function used to create an array to store a point values for each point within the grid bounds specified by the user
    # Inputs:   boundaries of the grid as specified by the user
    # Outputs:  returns an array (zeros) to store values for each grid point

    arr = []        # Initialize a blank array
    for i in range(int((field_bounds[1]+1)*(field_bounds[3]+1))):
        arr.append(0)       # For the number of grid spaces specified for the plane, create a corresponding array space to store its value

    # DEBUG
    # print(str(len(point_vals)))

    return arr      # Return the array

def field_sweep(oIDInfo):

    # Function used to sweep the imaginary grid placed over the field to determine high/low risk areas w.r.t. specified opponent
    # Inputs:   opponent ID information
    # Outputs:  modifies values within the "point value" array generated by bounds_to_arr function (modified using global call)

    global point_vals, field_bounds     # Aquire necessary global variables

    for i in range(field_bounds[1]+1):      # For each x coordinate in the grid
        for j in range(field_bounds[3]+1):      # For each y coordinate in the grid
            prox = point_prox(i, j, oIDInfo)        # Determine the proximity of the specified opponent to each point in the plane
            if (prox[0] < math.sqrt(2)) and (point_vals[i*(field_bounds[3] + 1)+j] < 1):
                point_vals[i*(field_bounds[3] + 1)+j] = point_vals[i*(field_bounds[3] + 1)+j] + 1       # If the point is within the specified magnitude and has not already been flagged, then flag it

def point_val_check(x, y):

    # Function called to check the appropriate value in the array associated with the point values of the array
    # Inputs:   x coordinate of interest
    #           y coordinate of interest
    # Outputs:  boulien value associated with grid location

    global field_bounds, point_vals     # Aquire necessary global variables

    arr = []        # Initialize a blank array
    # Following block creates an array to reference in order to find location in the point_vals array
    for i in range(field_bounds[1]+1):
        arr.append(i)
    for i in range(field_bounds[3]+1):
        arr.append(i)

    # DEBUG:
    # print(str(arr))

    status = point_vals[arr[x]*(field_bounds[3] + 1) + y]        # Access the appropriate flag in the point_vals array

    # DEBUG:
    # print(str(arr[x]*7 + arr[field_bounds[2] + y]))

    return status       # Return the flag (occupied/unoccupied) respectively (TRUE/FALSE)

def ser_check(aIDInfoC, aIDInfo2, oIDInfo, allied_flag):

    # Function used to check the imediate e,w,n,s coordinates (respectively) serounding the robot to check for a better scoring/passing position
    # Inputs:   controlled/passing robot
    #           receiving robot
    #           opponent of interest for interference
    # Ouptuts:  modifies a 4 element array holding the value/s of the associated serounding options for kicking/passing

    global net_location, point_vals, ser_check_vals, al_n

    aIDInfoOpt = [aIDInfoC[1] + 2, aIDInfoC[2], aIDInfoC[1] - 2, aIDInfoC[2], aIDInfoC[1], aIDInfoC[2] + 2, aIDInfoC[1], aIDInfoC[2] - 2]       # Create a reference for points serrounding the robot

    aIDInfoC1 = [1, aIDInfoC[1] + 2, aIDInfoC[2]]       # Point located at coordinate (x+1, y) w.r.t. current robot position
    aIDInfoC2 = [2, aIDInfoC[1] - 2, aIDInfoC[2]]       # Point located at coordinate (x-1, y) w.r.t. current robot position
    aIDInfoC3 = [3, aIDInfoC[1], aIDInfoC[2] + 2]       # Point located at coordinate (x, y+1) w.r.t. current robot position
    aIDInfoC4 = [4, aIDInfoC[1], aIDInfoC[2] - 2]       # Point located at coordinate (x, y-1) w.r.t. current robot position

    # Each of the following blocks below will evaluate one of the respective points above in the order listed. Done by
    # ensuring first that the position is within the bounds of the field limits, then checking if its risk flag
    # (point_vals) was tripped, and lastly the line of sight (net/opponent depending on location) is checked before its
    # value is either incremented (good location) or left unaltered (poor location) for the specified task.

    # Check location east or robot for LOS to net
    i = 0
    if (aIDInfoOpt[i * 2] <= field_bounds[1]-2) and not(point_val_check(aIDInfoOpt[i * 2], aIDInfoOpt[i * 2 + 1])) and check_LOS_net(aIDInfoC1, oIDInfo):
        ser_check_vals[i] = ser_check_vals[i] + 1
        # DEBUG
        # print"1++")

    # Check location west of robot for LOS to net
    i = i + 1
    if (aIDInfoOpt[i * 2] >= 0) and not(point_val_check(aIDInfoOpt[i * 2], aIDInfoOpt[i * 2 + 1])) and check_LOS_net(aIDInfoC2, oIDInfo):
        ser_check_vals[i] = ser_check_vals[i] + 1
        # DEBUG
        # print('\n2++\n')

    # Check location north of robot for LOS to ally
    if allied_flag:
        i = i + 1
        if (aIDInfoOpt[i * 2 + 1] <= field_bounds[3]-2) and not(point_val_check(aIDInfoOpt[i * 2], aIDInfoOpt[i * 2 + 1])) and check_LOS_al(aIDInfoC3, aIDInfo2, oIDInfo):
            ser_check_vals[i] = ser_check_vals[i] + 1
            # DEBUG
            # print('\n3++\n')

        # Check location south of robot for LOS to ally
        i = i + 1
        if (aIDInfoOpt[i * 2 + 1] >= 0) and not(point_val_check(aIDInfoOpt[i * 2], aIDInfoOpt[i * 2 + 1])) and check_LOS_al(aIDInfoC4, aIDInfo2, oIDInfo):
            ser_check_vals[i] = ser_check_vals[i] + 1
            # DEBUG
            # print('\n4++\n')

def op_rec_loc(aIDInfo, oIDInfo):
    # Function determines the top ____ locations from which to recieve a pass
    # Inputs:   ball possessor ID information
    #           opponent ID information of interest
    # Outputs:  modifies specified array of op_loc_values

    global op_loc_point_vals, net_location, point_vals, field_bounds  # Aquire necessary global variables

    # Check LOS for each point on grid between ball possessor and net

    # DEBUG:
    # k = 1

    for i in range(field_bounds[1] + 1):  # For each x  on grid
        for j in range(field_bounds[3] + 1):  # For each y point on grid
            dummy_id = [0, i, j]  # Create a temporary dummy robot id for function compatibility

            # DEBUG:
            # k = k + 1
            # print(str(i)+" and "+str(j)+" gives " + str(point_val_check(i, j)))
            # print(str(k))

            if not (point_val_check(i, j)) and check_LOS_al(aIDInfo, dummy_id, oIDInfo) and check_LOS_net(dummy_id,
                                                                                                          oIDInfo):  # If position not flagged, and LOS is clear to both the ball possessor and the net
                op_loc_point_vals[i * (field_bounds[3] + 1) + j] = op_loc_point_vals[i * (
                        field_bounds[3] + 1) + j] + 1  # Increase the locations "value"

    # Check proximity of each point to opponents and adjust their values according to a ratio determined by point proximity to an opponent
    for i in range(field_bounds[1] + 1):  # For each x point on grid
        for j in range(field_bounds[3] + 1):  # For each y point on grid
            prox = point_prox(i, j, oIDInfo)  # Check the proximity of the point
            if prox[0] <= 2:  # If within a specified unit
                op_loc_point_vals[i * (field_bounds[3] + 1) + j] = op_loc_point_vals[i * (
                        field_bounds[3] + 1) + j] * 0.90  # Reduce the points "value" by 90%
            elif prox[0] <= 3:  # If within two specified unit
                op_loc_point_vals[i * (field_bounds[3] + 1) + j] = op_loc_point_vals[i * (
                        field_bounds[3] + 1) + j] * 0.95  # Reduce the points "value" by 95%
            elif prox[0] <= 4:  # If within specified unit
                op_loc_point_vals[i * (field_bounds[3] + 1) + j] = op_loc_point_vals[
                                                                       i * (field_bounds[3] + 1) + j] * 0.97
            elif prox[0] <= 6:  # If within specified unit
                op_loc_point_vals[i * (field_bounds[3] + 1) + j] = op_loc_point_vals[
                                                                       i * (field_bounds[3] + 1) + j] * 0.99


def op_point_val_check(x, y):

    # Function called to check the appropriate value in the array associated with the point values of the array
    # Inputs:   x coordinate of interest
    #           y coordinate of interest
    # Outputs:  boulien value associated with grid location

    global field_bounds, op_loc_point_vals     # Aquire necessary global variables

    arr = []        # Initiate empty array

    # Following block creates a reference array for the function
    for i in range(field_bounds[1]+1):
        arr.append(i)
    for i in range(field_bounds[3]+1):
        arr.append(i)

    # DEBUG:
    # print(str(arr))

    val = op_loc_point_vals[arr[x]*(field_bounds[3] + 1) + y]       # Identify the correct position in the "value" array

    # DEBUG:
    # print(str(arr[x]*7 + arr[field_bounds[2] + y]))

    return val      # Return the appropriate value of the point

# STILL IN DEVELOPEMENT

def top_loc():
    global op_loc_point_vals, op_n, al_n, possessor_info

    # Select the top al_n*3 positions (1/ally on field)
    top_loc_values = []
    for i in range((al_n - 1) * 3):
        top_loc_values.append(0)

    # DEBUG:
    # print(str(top_loc_values))

    pos = []
    for i in range((al_n - 1) * 6):
        pos.append(0)
    # DEBUG:
    # print(str(pos))

    n = 0
    for i in range(field_bounds[1] + 1):
        for j in range(field_bounds[3] + 1):
            if n == 0 and op_point_val_check(i, j) > (op_n - 1) and j >= possessor_info[2]:
                top_loc_values[n] = op_point_val_check(i, j)
                pos[n] = i
                pos[n + 1] = j
                n = n + 1
            elif n == (al_n - 1) * 3:
                # Check point proximity to those already checked or too close to possessor in following block and flag to skip point if flag if tripped
                flag = 1
                prox_possessor = point_prox(i, j, possessor_info)
                for k in range(n):
                    prox = point_prox(i, j, [0, pos[k * 2], pos[k * 2 + 1]])
                    if prox[0] < 4 or prox_possessor[0] < 4 or j < possessor_info[2]:
                        flag = 0

                    # Flag locations too close to possessor***
                    if op_point_val_check(i, j) > top_loc_values[k] and flag:
                        top_loc_values[k] = op_point_val_check(i, j)
                        pos[k * 2] = i
                        pos[k * 2 + 1] = j
            elif n != 0:
                # Check point proximity to those already checked or too close to possessor in following block and flag to skip point if flag if tripped
                flag = 1
                prox_possessor = point_prox(i, j, possessor_info)
                for k in range(n):
                    prox = point_prox(i, j, [0, pos[k * 2], pos[k * 2 + 1]])
                    if prox[0] < 4 or prox_possessor[0] < 4 or j < possessor_info[2]:
                        flag = 0

                if op_point_val_check(i, j) > (op_n - 1) and flag:
                    top_loc_values[n] = op_point_val_check(i, j)
                    pos[n * 2] = i
                    pos[n * 2 + 1] = j
                    n = n + 1

    # DEBUG
    print(str(top_loc_values))
    return pos


def ser_val_loc_allocation(i, receiver_info, coords_arr_grd):

    global ser_check_vals

    for j in range(rob_num):
        if coords_arr_grd[j][0] == ball_possesor_id:
            if i == 0:
                coords_arr_grd[j][1] = coords_arr_grd[j][1] + 2
                ang = point_prox(coords_arr_grd[j][1], coords_arr_grd[j][2], [0, net_location[0], net_location[1]])
                coords_arr_grd[j][3] = ang[1]
            elif i == 1:
                coords_arr_grd[j][1] = coords_arr_grd[j][1] - 2
                ang = point_prox(coords_arr_grd[j][1], coords_arr_grd[j][2], [0, net_location[0], net_location[1]])
                coords_arr_grd[j][3] = ang[1]
            elif i == 2:
                coords_arr_grd[j][2] = coords_arr_grd[j][2] + 2
                ang = point_prox(coords_arr_grd[j][1], coords_arr_grd[j][2], receiver_info)
                coords_arr_grd[j][3] = ang[1]
            else:
                coords_arr_grd[j][2] = coords_arr_grd[j][2] - 2
                ang = point_prox(coords_arr_grd[j][1], coords_arr_grd[j][2], receiver_info)
                coords_arr_grd[j][3] = ang[1]
    
    return coords_arr_grd

def greater_loop_1(coords_arr_grd):

    global ball_possesor_id, rob_num, ser_check_vals, point_vals     # Aquire necessary global variables

    count_rob(coords_arr_grd)

    pos_flg = 0
    i = 0
    while i in range(rob_num) and not(pos_flg):
        if coords_arr_grd[i][0] == ball_possesor_id:
            pos_flg = 1
        i = i+1

    if pos_flg == 0:
        return coords_arr_grd

    for i in range(rob_num):
        # DEBUG:
        # print(str(coords_arr_grd[i][0] == ball_possesor_id))

        #All decisions related to the ball possesor
        if coords_arr_grd[i][0] == ball_possesor_id:
            possessor_info = coords_arr_grd[i]

            # Check if a shot can be taken from current location
            shot_stat = 0       # Initialize shot status flag (must reach op_n to allow a shot)
            for j in range(rob_num):

                # DEBUG:
                # print(str(j))
                # print(str(coords_arr_grd[i][0] != coords_arr_grd[j][0]))
                # print(str(not(coords_arr_grd[j][0] <= 16)))

                if coords_arr_grd[i][0] != coords_arr_grd[j][0] and not(coords_arr_grd[j][0] <= 16):
                    shot_stat = shot_stat + check_LOS_net(coords_arr_grd[i], coords_arr_grd[j])
                # DEBUG:
                # print(str(shot_stat))

            if shot_stat == op_n:
                print("SHOOT")
                for j in range(rob_num):
                    if coords_arr_grd[j][0] == ball_possesor_id:
                        ang = point_prox(coords_arr_grd[j][1], coords_arr_grd[j][2], [0, net_location[0], net_location[1]])
                        coords_arr_grd[j][3] = ang[1]
                return coords_arr_grd
            # *******************************************************************
            # Check if a pass can be made from current location
            pass_stat = 0       # Initialize pass status flag (must reach op_n to allow a pass)
            if al_n > 1:
                for j in range(rob_num):
                    # Check if allied id and not passer
                    if coords_arr_grd[i][0] != coords_arr_grd[j][0] and coords_arr_grd[j][0] <= 16:
                        receiver_info = coords_arr_grd[j]
                        for k in range(rob_num):
                            # Check if opponent is in way of receiver
                            if not(coords_arr_grd[k][0] <= 16):
                                pass_stat = pass_stat + check_LOS_al(coords_arr_grd[i], coords_arr_grd[j], coords_arr_grd[k])

                                # DEBUG:
                                # print(str(pass_stat))

            if pass_stat == op_n:
                print("PASS")
                print(possessor_info)
                print(receiver_info)
                ang = point_prox(possessor_info[1], possessor_info[2], receiver_info)
                print(ang[1])
                for j in range(rob_num):
                    if coords_arr_grd[j][0] == ball_possesor_id:
                        if ang[1] > 0:
                            ang[1] = ang[1] - 180
                        else:
                            ang[1] = ang[1] + 180
                        coords_arr_grd[j][3] = ang[1]
                        
                    elif coords_arr_grd[j][0] == receiver_info[0]:
                        coords_arr_grd[j][3] = ang[1]
                return coords_arr_grd
            # *******************************************************************
            # Check if immediate surroundings offer a better position from which to shoot or pass
            allied_flag = 1

            if al_n == 1:
                coords_arr_grd.append([0, 0, 0, 0])
                allied_flag = 0
                rob_num = rob_num + 1

            for j in range(rob_num):
                ser_check_vals = [0, 0, 0, 0]
                # Check if not possessor and allied
                if coords_arr_grd[i][0] != coords_arr_grd[j][0] and coords_arr_grd[j][0] <= 16:
                    # For each passable ally, run ser check value (will pick first possible option as of right now)
                    receiver_info = []
                    for k in range(rob_num):
                        if not(coords_arr_grd[k][0] <= 16):
                            ser_check(coords_arr_grd[i], coords_arr_grd[j], coords_arr_grd[k], allied_flag)
                            receiver_info = coords_arr_grd[j]

                        # DEBUG:
                        # print(str(ser_check_vals))

                    if allied_flag == 0:
                        rob_num = rob_num - 1

                    for i in range(4):
                        if ser_check_vals[i] == op_n:
                            coords_arr_grd = ser_val_loc_allocation(i, receiver_info, coords_arr_grd)
                            print("SUR_CHECK")
                            return coords_arr_grd

            # ********************************************************************
            # Fail criteria
            print('LAST RESORT: SHOOT')
            for j in range(rob_num):
                if coords_arr_grd[j][0] == ball_possesor_id:
                    ang = point_prox(coords_arr_grd[j][1], coords_arr_grd[j][2], [0, net_location[0], net_location[1]])
                    coords_arr_grd[j][3] = ang[1]
            return coords_arr_grd

def greater_loop_2(coords_arr_grd):
    global possessor_info, ball_possesor_id, op_loc_point_vals  # Aquire necessary global variables

    pos_flg = 0
    i = 0
    while i in range(rob_num) and not(pos_flg):
        if coords_arr_grd[i][0] == ball_possesor_id:
            pos_flg = 1
        i = i+1

    if pos_flg == 0:
        return coords_arr_grd

    for i in range(rob_num):
        if coords_arr_grd[i][0] > 16:
            field_sweep(coords_arr_grd[i])

    # Following statement finds ball possessor and runs the optimal receiving location function using his information
    for i in range(rob_num):
        if coords_arr_grd[i][0] < 16:
            op_rec_loc(possessor_info, coords_arr_grd[i])

    top_locations = top_loc()  # Finds the top locations based on the optimal locations field sweep
    print(str(top_locations))
    # Initiate an array in which to allocate a location to a robot
    allocation_arr = []
    for i in range((al_n - 1) * 3):
        allocation_arr.append(1)

    clossest_point = [0, 0]  # Initiate an array for clossest points to the robot in question for the loop
    place_holder = [0, 0, 0, 0]
    for j in range(rob_num):
        prox_old = [100, 0]  # Initiate comparison point
        for i in range((al_n - 1) * 3):
            used_flag = -1  # Set a flag to be tripped if a location has been chosen for a robot so as not to double assign locations to more than one robot
            if allocation_arr[i] != 0 and coords_arr_grd[j][0] != ball_possesor_id and coords_arr_grd[j][
                0] <= 16:  # Chack that location has not already been assigned from top locations & not applying function to ball possessor & that robot is ally
                prox_new = point_prox(top_locations[i * 2], top_locations[i * 2 + 1], coords_arr_grd[
                    j])  # Compare each point to one another and determine which is clossest
                if prox_new[0] < prox_old[0]:  # If point is closer than previous
                    used_flag = i  # Indicate the used point
                    clossest_point[0] = top_locations[i * 2]  # Grab the x coordinate
                    clossest_point[1] = top_locations[i * 2 + 1]  # Grab the y coordinate

                    prox_old = prox_new  # Remember previous point for comparison to next

                    # DEBUG
                    # print(str(clossest_point))

                    place_holder[1] = clossest_point[0]  # Indicate new location for robot (xcoord)
                    place_holder[2] = clossest_point[1]  # Indicate new location for robot (ycoord)
                    ang = point_prox(clossest_point[0], clossest_point[1], possessor_info)
                    place_holder[3] = -ang[1]

                coords_arr_grd[j][1] = place_holder[1]
                coords_arr_grd[j][2] = place_holder[2]
                coords_arr_grd[j][3] = place_holder[3]

    allocation_arr[
        used_flag] = 0  # Trip the allocation_arr at the used_flag location so as not to double assign locations to two robots

    return coords_arr_grd  # Return the updater array with new robot locations

# SPECIFY GAME STRATEGY:

game_strat = "OFF"                              # Specify offensive or defensive strategy (OFF/DEF)

# GENERAL VARIABLES:
pxl_size = (640, 480)                           # Pixel size of camera view
field_bounds = [0, 13, 0, 10]                   # Specify field boundaries
net_location = (6.5, 10)                        # Specify net location on the grid
pxl_grd_ratio = grid_to_pxl_ratio()             # Determine the multiplication factor necessary to move from grid coordinates to pixel coordinates

# NON-USER DEFINED VARIABLES:
ser_check_vals = [0, 0, 0, 0]                   # Modifiable array in ser_check values
point_vals = bounds_to_arr(field_bounds)        # Modifiable array in field_sweep function
op_loc_point_vals = bounds_to_arr(field_bounds) # Modifiable array in op_rec_loc function
possession_flag = 1                             # A flag to determine weather our team is in possession of the ball
ball_possesor_id = 10 # coords_arr[0][0]             # remember id of the robot with possession of the ball
possessor_info = [10, 0, 4, 20]
receiver_id = 0
rob_num = 0                                     # Remember number of robots identified on field
al_n = 0
op_n = 0


if __name__== "__main__":
    run()
    cv2.destroyAllWindows()